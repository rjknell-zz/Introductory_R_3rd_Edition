<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 13 What is statistical testing? | Introductory R: A beginner’s guide to programming, data visualisation and statistical analysis in R</title>
  <meta name="description" content="null" />
  <meta name="generator" content="bookdown 0.18 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 13 What is statistical testing? | Introductory R: A beginner’s guide to programming, data visualisation and statistical analysis in R" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="null" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 13 What is statistical testing? | Introductory R: A beginner’s guide to programming, data visualisation and statistical analysis in R" />
  
  <meta name="twitter:description" content="null" />
  

<meta name="author" content="Rob Knell" />


<meta name="date" content="2020-07-29" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="basic-statistical-concepts.html"/>
<link rel="next" href="the-chi-squared-test-and-a-classic-dataset-on-smoking-and-cancer.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Introductory R</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Preface</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#why-this-book"><i class="fa fa-check"></i><b>1.1</b> Why this book?</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#how-to-use-this-book"><i class="fa fa-check"></i><b>1.2</b> How to use this book</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#acknowledgements"><i class="fa fa-check"></i><b>1.3</b> Acknowledgements</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="a-first-r-session.html"><a href="a-first-r-session.html"><i class="fa fa-check"></i><b>2</b> A first R session</a><ul>
<li class="chapter" data-level="2.1" data-path="a-first-r-session.html"><a href="a-first-r-session.html#what-is-r"><i class="fa fa-check"></i><b>2.1</b> What is R?</a></li>
<li class="chapter" data-level="2.2" data-path="a-first-r-session.html"><a href="a-first-r-session.html#a-first-r-session-1"><i class="fa fa-check"></i><b>2.2</b> A first R session</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="basics-arithmetic-objects-and-functions.html"><a href="basics-arithmetic-objects-and-functions.html"><i class="fa fa-check"></i><b>3</b> Basics: arithmetic, objects and functions</a><ul>
<li class="chapter" data-level="3.0.1" data-path="basics-arithmetic-objects-and-functions.html"><a href="basics-arithmetic-objects-and-functions.html#arithmetic"><i class="fa fa-check"></i><b>3.0.1</b> Arithmetic</a></li>
<li class="chapter" data-level="3.0.2" data-path="basics-arithmetic-objects-and-functions.html"><a href="basics-arithmetic-objects-and-functions.html#logical-operations"><i class="fa fa-check"></i><b>3.0.2</b> Logical operations</a></li>
<li class="chapter" data-level="3.0.3" data-path="basics-arithmetic-objects-and-functions.html"><a href="basics-arithmetic-objects-and-functions.html#objects"><i class="fa fa-check"></i><b>3.0.3</b> Objects</a></li>
<li class="chapter" data-level="3.1" data-path="basics-arithmetic-objects-and-functions.html"><a href="basics-arithmetic-objects-and-functions.html#kinds-of-data"><i class="fa fa-check"></i><b>3.1</b> Kinds of data</a></li>
<li class="chapter" data-level="3.2" data-path="basics-arithmetic-objects-and-functions.html"><a href="basics-arithmetic-objects-and-functions.html#whats-in-my-workspace"><i class="fa fa-check"></i><b>3.2</b> What’s in my workspace?</a><ul>
<li class="chapter" data-level="3.2.1" data-path="basics-arithmetic-objects-and-functions.html"><a href="basics-arithmetic-objects-and-functions.html#functions"><i class="fa fa-check"></i><b>3.2.1</b> Functions</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="basics-arithmetic-objects-and-functions.html"><a href="basics-arithmetic-objects-and-functions.html#exercises"><i class="fa fa-check"></i><b>3.3</b> Exercises</a><ul>
<li class="chapter" data-level="3.3.1" data-path="basics-arithmetic-objects-and-functions.html"><a href="basics-arithmetic-objects-and-functions.html#calculations"><i class="fa fa-check"></i><b>3.3.1</b> Calculations</a></li>
<li class="chapter" data-level="3.3.2" data-path="basics-arithmetic-objects-and-functions.html"><a href="basics-arithmetic-objects-and-functions.html#objects-1"><i class="fa fa-check"></i><b>3.3.2</b> Objects</a></li>
<li class="chapter" data-level="3.3.3" data-path="basics-arithmetic-objects-and-functions.html"><a href="basics-arithmetic-objects-and-functions.html#functions-1"><i class="fa fa-check"></i><b>3.3.3</b> Functions</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="basics-arithmetic-objects-and-functions.html"><a href="basics-arithmetic-objects-and-functions.html#answers-to-exercises"><i class="fa fa-check"></i><b>3.4</b> Answers to exercises</a><ul>
<li class="chapter" data-level="3.4.1" data-path="basics-arithmetic-objects-and-functions.html"><a href="basics-arithmetic-objects-and-functions.html#calculations-1"><i class="fa fa-check"></i><b>3.4.1</b> Calculations</a></li>
<li class="chapter" data-level="3.4.2" data-path="basics-arithmetic-objects-and-functions.html"><a href="basics-arithmetic-objects-and-functions.html#objects-2"><i class="fa fa-check"></i><b>3.4.2</b> Objects</a></li>
<li class="chapter" data-level="3.4.3" data-path="basics-arithmetic-objects-and-functions.html"><a href="basics-arithmetic-objects-and-functions.html#functions-2"><i class="fa fa-check"></i><b>3.4.3</b> Functions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="data-vectors-matrices-and-data-frames.html"><a href="data-vectors-matrices-and-data-frames.html"><i class="fa fa-check"></i><b>4</b> Data: Vectors, Matrices and Data Frames</a><ul>
<li class="chapter" data-level="4.1" data-path="data-vectors-matrices-and-data-frames.html"><a href="data-vectors-matrices-and-data-frames.html#vectors"><i class="fa fa-check"></i><b>4.1</b> Vectors</a></li>
<li class="chapter" data-level="4.2" data-path="data-vectors-matrices-and-data-frames.html"><a href="data-vectors-matrices-and-data-frames.html#matrices"><i class="fa fa-check"></i><b>4.2</b> Matrices</a></li>
<li class="chapter" data-level="4.3" data-path="data-vectors-matrices-and-data-frames.html"><a href="data-vectors-matrices-and-data-frames.html#factors-and-data-frames"><i class="fa fa-check"></i><b>4.3</b> Factors and Data frames</a></li>
<li class="chapter" data-level="4.4" data-path="data-vectors-matrices-and-data-frames.html"><a href="data-vectors-matrices-and-data-frames.html#exercises-1"><i class="fa fa-check"></i><b>4.4</b> Exercises</a><ul>
<li class="chapter" data-level="4.4.1" data-path="data-vectors-matrices-and-data-frames.html"><a href="data-vectors-matrices-and-data-frames.html#vectors-1"><i class="fa fa-check"></i><b>4.4.1</b> Vectors</a></li>
<li class="chapter" data-level="4.4.2" data-path="data-vectors-matrices-and-data-frames.html"><a href="data-vectors-matrices-and-data-frames.html#matrices-1"><i class="fa fa-check"></i><b>4.4.2</b> Matrices</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="data-vectors-matrices-and-data-frames.html"><a href="data-vectors-matrices-and-data-frames.html#answers-to-exercises-1"><i class="fa fa-check"></i><b>4.5</b> Answers to exercises</a><ul>
<li class="chapter" data-level="4.5.1" data-path="data-vectors-matrices-and-data-frames.html"><a href="data-vectors-matrices-and-data-frames.html#vectors-2"><i class="fa fa-check"></i><b>4.5.1</b> Vectors</a></li>
<li class="chapter" data-level="4.5.2" data-path="data-vectors-matrices-and-data-frames.html"><a href="data-vectors-matrices-and-data-frames.html#matrices-2"><i class="fa fa-check"></i><b>4.5.2</b> Matrices</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="choosing-data-subscripts-and-subsetting.html"><a href="choosing-data-subscripts-and-subsetting.html"><i class="fa fa-check"></i><b>5</b> Choosing data: subscripts and subsetting</a><ul>
<li class="chapter" data-level="5.0.1" data-path="choosing-data-subscripts-and-subsetting.html"><a href="choosing-data-subscripts-and-subsetting.html#subscripts"><i class="fa fa-check"></i><b>5.0.1</b> Subscripts</a></li>
<li class="chapter" data-level="5.0.2" data-path="choosing-data-subscripts-and-subsetting.html"><a href="choosing-data-subscripts-and-subsetting.html#boolean-logic-and-more-complex-subscripting"><i class="fa fa-check"></i><b>5.0.2</b> Boolean logic and more complex subscripting</a></li>
<li class="chapter" data-level="5.0.3" data-path="choosing-data-subscripts-and-subsetting.html"><a href="choosing-data-subscripts-and-subsetting.html#subscripts-in-matrices-and-data-frames"><i class="fa fa-check"></i><b>5.0.3</b> Subscripts in matrices and data frames</a></li>
<li class="chapter" data-level="5.0.4" data-path="choosing-data-subscripts-and-subsetting.html"><a href="choosing-data-subscripts-and-subsetting.html#subset"><i class="fa fa-check"></i><b>5.0.4</b> Subset</a></li>
<li class="chapter" data-level="5.1" data-path="choosing-data-subscripts-and-subsetting.html"><a href="choosing-data-subscripts-and-subsetting.html#exercises-2"><i class="fa fa-check"></i><b>5.1</b> Exercises</a><ul>
<li class="chapter" data-level="5.1.1" data-path="choosing-data-subscripts-and-subsetting.html"><a href="choosing-data-subscripts-and-subsetting.html#subscripts-and-vectors"><i class="fa fa-check"></i><b>5.1.1</b> Subscripts and vectors</a></li>
<li class="chapter" data-level="5.1.2" data-path="choosing-data-subscripts-and-subsetting.html"><a href="choosing-data-subscripts-and-subsetting.html#subscripts-and-matrices"><i class="fa fa-check"></i><b>5.1.2</b> Subscripts and matrices</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="choosing-data-subscripts-and-subsetting.html"><a href="choosing-data-subscripts-and-subsetting.html#answers-to-exercises-2"><i class="fa fa-check"></i><b>5.2</b> Answers to exercises</a><ul>
<li class="chapter" data-level="5.2.1" data-path="choosing-data-subscripts-and-subsetting.html"><a href="choosing-data-subscripts-and-subsetting.html#subscripts-and-vectors-1"><i class="fa fa-check"></i><b>5.2.1</b> Subscripts and vectors</a></li>
<li class="chapter" data-level="5.2.2" data-path="choosing-data-subscripts-and-subsetting.html"><a href="choosing-data-subscripts-and-subsetting.html#subscripts-and-matrices-1"><i class="fa fa-check"></i><b>5.2.2</b> Subscripts and matrices</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="r-scripts-and-your-r-workflow.html"><a href="r-scripts-and-your-r-workflow.html"><i class="fa fa-check"></i><b>6</b> R scripts and your R workflow</a><ul>
<li class="chapter" data-level="6.1" data-path="r-scripts-and-your-r-workflow.html"><a href="r-scripts-and-your-r-workflow.html#writing-and-using-r-scripts"><i class="fa fa-check"></i><b>6.1</b> Writing and using R scripts</a></li>
<li class="chapter" data-level="6.2" data-path="r-scripts-and-your-r-workflow.html"><a href="r-scripts-and-your-r-workflow.html#running-code-from-an-r-script-window"><i class="fa fa-check"></i><b>6.2</b> Running code from an R script window</a></li>
<li class="chapter" data-level="6.3" data-path="r-scripts-and-your-r-workflow.html"><a href="r-scripts-and-your-r-workflow.html#running-code-from-files-using-source"><i class="fa fa-check"></i><b>6.3</b> Running code from files using <code>source()</code></a></li>
<li class="chapter" data-level="6.4" data-path="r-scripts-and-your-r-workflow.html"><a href="r-scripts-and-your-r-workflow.html#workflow-structure-or-what-should-i-put-in-my-script"><i class="fa fa-check"></i><b>6.4</b> Workflow structure, or what should I put in my script?</a></li>
<li class="chapter" data-level="6.5" data-path="r-scripts-and-your-r-workflow.html"><a href="r-scripts-and-your-r-workflow.html#keep-it-neat-making-your-script-easy-to-read"><i class="fa fa-check"></i><b>6.5</b> Keep it neat — making your script easy to read</a></li>
<li class="chapter" data-level="6.6" data-path="r-scripts-and-your-r-workflow.html"><a href="r-scripts-and-your-r-workflow.html#i-wish-i-hadnt-commented-my-code-so-much-said-no-one-ever-4."><i class="fa fa-check"></i><b>6.6</b> “I wish I hadn’t commented my code so much”, said no-one, ever.</a></li>
<li class="chapter" data-level="6.7" data-path="r-scripts-and-your-r-workflow.html"><a href="r-scripts-and-your-r-workflow.html#using-rstudio-to-write-scripts"><i class="fa fa-check"></i><b>6.7</b> Using RStudio to write scripts</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="help-files-and-packages.html"><a href="help-files-and-packages.html"><i class="fa fa-check"></i><b>7</b> Help files and packages</a><ul>
<li class="chapter" data-level="7.1" data-path="help-files-and-packages.html"><a href="help-files-and-packages.html#using-the-help-files"><i class="fa fa-check"></i><b>7.1</b> Using the help files</a></li>
<li class="chapter" data-level="7.2" data-path="help-files-and-packages.html"><a href="help-files-and-packages.html#packages"><i class="fa fa-check"></i><b>7.2</b> Packages</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="importing-data.html"><a href="importing-data.html"><i class="fa fa-check"></i><b>8</b> Importing Data</a><ul>
<li class="chapter" data-level="8.1" data-path="importing-data.html"><a href="importing-data.html#the-rules"><i class="fa fa-check"></i><b>8.1</b> The Rules</a></li>
<li class="chapter" data-level="8.2" data-path="importing-data.html"><a href="importing-data.html#importing-your-text-file"><i class="fa fa-check"></i><b>8.2</b> Importing your Text File</a><ul>
<li class="chapter" data-level="8.2.1" data-path="importing-data.html"><a href="importing-data.html#the-simple-way"><i class="fa fa-check"></i><b>8.2.1</b> The simple way</a></li>
<li class="chapter" data-level="8.2.2" data-path="importing-data.html"><a href="importing-data.html#the-less-simple-way"><i class="fa fa-check"></i><b>8.2.2</b> The less simple way</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="importing-data.html"><a href="importing-data.html#importing-character-data"><i class="fa fa-check"></i><b>8.3</b> Importing character data</a></li>
<li class="chapter" data-level="8.4" data-path="importing-data.html"><a href="importing-data.html#data-on-the-web"><i class="fa fa-check"></i><b>8.4</b> Data on the web</a></li>
<li class="chapter" data-level="8.5" data-path="importing-data.html"><a href="importing-data.html#using-read.table"><i class="fa fa-check"></i><b>8.5</b> Using <code>read.table()</code></a></li>
<li class="chapter" data-level="8.6" data-path="importing-data.html"><a href="importing-data.html#what-to-do-once-youve-managed-to-import-your-data."><i class="fa fa-check"></i><b>8.6</b> What to do once you’ve managed to import your data.</a></li>
<li class="chapter" data-level="8.7" data-path="importing-data.html"><a href="importing-data.html#importing-data-directly-from-excel"><i class="fa fa-check"></i><b>8.7</b> Importing data directly from Excel</a></li>
<li class="chapter" data-level="8.8" data-path="importing-data.html"><a href="importing-data.html#other-data-formats"><i class="fa fa-check"></i><b>8.8</b> Other data formats</a></li>
<li class="chapter" data-level="8.9" data-path="importing-data.html"><a href="importing-data.html#importing-data-into-rstudio"><i class="fa fa-check"></i><b>8.9</b> Importing data into RStudio</a></li>
<li class="chapter" data-level="8.10" data-path="importing-data.html"><a href="importing-data.html#to-attach-or-not-to-attach"><i class="fa fa-check"></i><b>8.10</b> To attach or not to attach?</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="r-graphics-i-drawing-graphs-and-changing-plot-symbols-and-colours-using-the-base-graphics-system.html"><a href="r-graphics-i-drawing-graphs-and-changing-plot-symbols-and-colours-using-the-base-graphics-system.html"><i class="fa fa-check"></i><b>9</b> R graphics I — drawing graphs and changing plot symbols and colours using the base graphics system</a><ul>
<li class="chapter" data-level="9.1" data-path="r-graphics-i-drawing-graphs-and-changing-plot-symbols-and-colours-using-the-base-graphics-system.html"><a href="r-graphics-i-drawing-graphs-and-changing-plot-symbols-and-colours-using-the-base-graphics-system.html#base-graphics-versus-ggplot2-versus-lattice-versus-whaaat"><i class="fa fa-check"></i><b>9.1</b> Base graphics versus ggplot2 versus lattice versus whaaat???</a></li>
<li class="chapter" data-level="9.2" data-path="r-graphics-i-drawing-graphs-and-changing-plot-symbols-and-colours-using-the-base-graphics-system.html"><a href="r-graphics-i-drawing-graphs-and-changing-plot-symbols-and-colours-using-the-base-graphics-system.html#base-graphics-example-ufo-reports-again"><i class="fa fa-check"></i><b>9.2</b> Base graphics example: UFO reports again</a></li>
<li class="chapter" data-level="9.3" data-path="r-graphics-i-drawing-graphs-and-changing-plot-symbols-and-colours-using-the-base-graphics-system.html"><a href="r-graphics-i-drawing-graphs-and-changing-plot-symbols-and-colours-using-the-base-graphics-system.html#scatterplots"><i class="fa fa-check"></i><b>9.3</b> Scatterplots</a></li>
<li class="chapter" data-level="9.4" data-path="r-graphics-i-drawing-graphs-and-changing-plot-symbols-and-colours-using-the-base-graphics-system.html"><a href="r-graphics-i-drawing-graphs-and-changing-plot-symbols-and-colours-using-the-base-graphics-system.html#plot-symbols"><i class="fa fa-check"></i><b>9.4</b> Plot symbols</a></li>
<li class="chapter" data-level="9.5" data-path="r-graphics-i-drawing-graphs-and-changing-plot-symbols-and-colours-using-the-base-graphics-system.html"><a href="r-graphics-i-drawing-graphs-and-changing-plot-symbols-and-colours-using-the-base-graphics-system.html#colours"><i class="fa fa-check"></i><b>9.5</b> Colours</a></li>
<li class="chapter" data-level="9.6" data-path="r-graphics-i-drawing-graphs-and-changing-plot-symbols-and-colours-using-the-base-graphics-system.html"><a href="r-graphics-i-drawing-graphs-and-changing-plot-symbols-and-colours-using-the-base-graphics-system.html#plotting-multiple-symbols-or-colours"><i class="fa fa-check"></i><b>9.6</b> Plotting multiple symbols or colours</a></li>
<li class="chapter" data-level="9.7" data-path="r-graphics-i-drawing-graphs-and-changing-plot-symbols-and-colours-using-the-base-graphics-system.html"><a href="r-graphics-i-drawing-graphs-and-changing-plot-symbols-and-colours-using-the-base-graphics-system.html#colour-palettes-in-r"><i class="fa fa-check"></i><b>9.7</b> Colour palettes in R</a></li>
<li class="chapter" data-level="9.8" data-path="r-graphics-i-drawing-graphs-and-changing-plot-symbols-and-colours-using-the-base-graphics-system.html"><a href="r-graphics-i-drawing-graphs-and-changing-plot-symbols-and-colours-using-the-base-graphics-system.html#using-transparency-in-your-graphs"><i class="fa fa-check"></i><b>9.8</b> Using transparency in your graphs</a></li>
<li class="chapter" data-level="9.9" data-path="r-graphics-i-drawing-graphs-and-changing-plot-symbols-and-colours-using-the-base-graphics-system.html"><a href="r-graphics-i-drawing-graphs-and-changing-plot-symbols-and-colours-using-the-base-graphics-system.html#histograms-and-multiple-plots-in-the-same-window"><i class="fa fa-check"></i><b>9.9</b> Histograms and multiple plots in the same window</a></li>
<li class="chapter" data-level="9.10" data-path="r-graphics-i-drawing-graphs-and-changing-plot-symbols-and-colours-using-the-base-graphics-system.html"><a href="r-graphics-i-drawing-graphs-and-changing-plot-symbols-and-colours-using-the-base-graphics-system.html#boxplots"><i class="fa fa-check"></i><b>9.10</b> Boxplots</a></li>
<li class="chapter" data-level="9.11" data-path="r-graphics-i-drawing-graphs-and-changing-plot-symbols-and-colours-using-the-base-graphics-system.html"><a href="r-graphics-i-drawing-graphs-and-changing-plot-symbols-and-colours-using-the-base-graphics-system.html#bar-charts"><i class="fa fa-check"></i><b>9.11</b> Bar charts</a><ul>
<li class="chapter" data-level="9.11.1" data-path="r-graphics-i-drawing-graphs-and-changing-plot-symbols-and-colours-using-the-base-graphics-system.html"><a href="r-graphics-i-drawing-graphs-and-changing-plot-symbols-and-colours-using-the-base-graphics-system.html#more-complex-barplots"><i class="fa fa-check"></i><b>9.11.1</b> More complex barplots</a></li>
</ul></li>
<li class="chapter" data-level="9.12" data-path="r-graphics-i-drawing-graphs-and-changing-plot-symbols-and-colours-using-the-base-graphics-system.html"><a href="r-graphics-i-drawing-graphs-and-changing-plot-symbols-and-colours-using-the-base-graphics-system.html#other-types-of-plot"><i class="fa fa-check"></i><b>9.12</b> Other types of plot</a><ul>
<li class="chapter" data-level="9.12.1" data-path="r-graphics-i-drawing-graphs-and-changing-plot-symbols-and-colours-using-the-base-graphics-system.html"><a href="r-graphics-i-drawing-graphs-and-changing-plot-symbols-and-colours-using-the-base-graphics-system.html#histogram-with-overlaid-probability-density-estimate"><i class="fa fa-check"></i><b>9.12.1</b> Histogram with overlaid probability density estimate</a></li>
<li class="chapter" data-level="9.12.2" data-path="r-graphics-i-drawing-graphs-and-changing-plot-symbols-and-colours-using-the-base-graphics-system.html"><a href="r-graphics-i-drawing-graphs-and-changing-plot-symbols-and-colours-using-the-base-graphics-system.html#pie-graph"><i class="fa fa-check"></i><b>9.12.2</b> Pie graph</a></li>
<li class="chapter" data-level="9.12.3" data-path="r-graphics-i-drawing-graphs-and-changing-plot-symbols-and-colours-using-the-base-graphics-system.html"><a href="r-graphics-i-drawing-graphs-and-changing-plot-symbols-and-colours-using-the-base-graphics-system.html#d-scatterplot"><i class="fa fa-check"></i><b>9.12.3</b> 3D scatterplot</a></li>
<li class="chapter" data-level="9.12.4" data-path="r-graphics-i-drawing-graphs-and-changing-plot-symbols-and-colours-using-the-base-graphics-system.html"><a href="r-graphics-i-drawing-graphs-and-changing-plot-symbols-and-colours-using-the-base-graphics-system.html#contour-plot"><i class="fa fa-check"></i><b>9.12.4</b> Contour plot</a></li>
</ul></li>
<li class="chapter" data-level="9.13" data-path="r-graphics-i-drawing-graphs-and-changing-plot-symbols-and-colours-using-the-base-graphics-system.html"><a href="r-graphics-i-drawing-graphs-and-changing-plot-symbols-and-colours-using-the-base-graphics-system.html#exporting-graphics"><i class="fa fa-check"></i><b>9.13</b> Exporting Graphics</a><ul>
<li class="chapter" data-level="9.13.1" data-path="r-graphics-i-drawing-graphs-and-changing-plot-symbols-and-colours-using-the-base-graphics-system.html"><a href="r-graphics-i-drawing-graphs-and-changing-plot-symbols-and-colours-using-the-base-graphics-system.html#the-easy-way"><i class="fa fa-check"></i><b>9.13.1</b> The easy way</a></li>
<li class="chapter" data-level="9.13.2" data-path="r-graphics-i-drawing-graphs-and-changing-plot-symbols-and-colours-using-the-base-graphics-system.html"><a href="r-graphics-i-drawing-graphs-and-changing-plot-symbols-and-colours-using-the-base-graphics-system.html#the-hard-way"><i class="fa fa-check"></i><b>9.13.2</b> The hard way</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="r-graphics-ii-adding-elements-to-an-existing-graph.html"><a href="r-graphics-ii-adding-elements-to-an-existing-graph.html"><i class="fa fa-check"></i><b>10</b> R graphics II — Adding elements to an existing graph</a><ul>
<li class="chapter" data-level="10.1" data-path="r-graphics-ii-adding-elements-to-an-existing-graph.html"><a href="r-graphics-ii-adding-elements-to-an-existing-graph.html#simple-regression-lines"><i class="fa fa-check"></i><b>10.1</b> Simple regression lines</a></li>
<li class="chapter" data-level="10.2" data-path="r-graphics-ii-adding-elements-to-an-existing-graph.html"><a href="r-graphics-ii-adding-elements-to-an-existing-graph.html#multiple-regression-lines"><i class="fa fa-check"></i><b>10.2</b> Multiple regression lines</a></li>
<li class="chapter" data-level="10.3" data-path="r-graphics-ii-adding-elements-to-an-existing-graph.html"><a href="r-graphics-ii-adding-elements-to-an-existing-graph.html#legends"><i class="fa fa-check"></i><b>10.3</b> Legends</a></li>
<li class="chapter" data-level="10.4" data-path="r-graphics-ii-adding-elements-to-an-existing-graph.html"><a href="r-graphics-ii-adding-elements-to-an-existing-graph.html#curves"><i class="fa fa-check"></i><b>10.4</b> Curves</a><ul>
<li class="chapter" data-level="10.4.1" data-path="r-graphics-ii-adding-elements-to-an-existing-graph.html"><a href="r-graphics-ii-adding-elements-to-an-existing-graph.html#adding-a-curve-using-curve"><i class="fa fa-check"></i><b>10.4.1</b> Adding a curve using <code>curve()</code></a></li>
<li class="chapter" data-level="10.4.2" data-path="r-graphics-ii-adding-elements-to-an-existing-graph.html"><a href="r-graphics-ii-adding-elements-to-an-existing-graph.html#adding-a-curve-using-lines-or-points."><i class="fa fa-check"></i><b>10.4.2</b> Adding a curve using <code>lines()</code> or <code>points()</code>.</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="r-graphics-ii-adding-elements-to-an-existing-graph.html"><a href="r-graphics-ii-adding-elements-to-an-existing-graph.html#text-and-arrows"><i class="fa fa-check"></i><b>10.5</b> Text and arrows</a></li>
<li class="chapter" data-level="10.6" data-path="r-graphics-ii-adding-elements-to-an-existing-graph.html"><a href="r-graphics-ii-adding-elements-to-an-existing-graph.html#confidence-bands-for-fitted-lines"><i class="fa fa-check"></i><b>10.6</b> Confidence bands for fitted lines</a><ul>
<li class="chapter" data-level="10.6.1" data-path="r-graphics-ii-adding-elements-to-an-existing-graph.html"><a href="r-graphics-ii-adding-elements-to-an-existing-graph.html#adding-confidence-bands-using-lines"><i class="fa fa-check"></i><b>10.6.1</b> Adding confidence bands using <code>lines()</code></a></li>
<li class="chapter" data-level="10.6.2" data-path="r-graphics-ii-adding-elements-to-an-existing-graph.html"><a href="r-graphics-ii-adding-elements-to-an-existing-graph.html#adding-confidence-intervals-to-fitted-lines-using-polygon"><i class="fa fa-check"></i><b>10.6.2</b> Adding confidence intervals to fitted lines using <code>polygon()</code></a></li>
</ul></li>
<li class="chapter" data-level="10.7" data-path="r-graphics-ii-adding-elements-to-an-existing-graph.html"><a href="r-graphics-ii-adding-elements-to-an-existing-graph.html#error-bars"><i class="fa fa-check"></i><b>10.7</b> Error bars</a><ul>
<li class="chapter" data-level="10.7.1" data-path="r-graphics-ii-adding-elements-to-an-existing-graph.html"><a href="r-graphics-ii-adding-elements-to-an-existing-graph.html#adding-error-bars-using-arrows"><i class="fa fa-check"></i><b>10.7.1</b> Adding error bars using <code>arrows()</code></a></li>
<li class="chapter" data-level="10.7.2" data-path="r-graphics-ii-adding-elements-to-an-existing-graph.html"><a href="r-graphics-ii-adding-elements-to-an-existing-graph.html#plotting-means-and-error-bars-using-plotmeans"><i class="fa fa-check"></i><b>10.7.2</b> Plotting means and error bars using <code>plotmeans()</code></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="graphics-with-ggplot2.html"><a href="graphics-with-ggplot2.html"><i class="fa fa-check"></i><b>11</b> Graphics with ggplot2</a><ul>
<li class="chapter" data-level="11.1" data-path="graphics-with-ggplot2.html"><a href="graphics-with-ggplot2.html#ggplot2-introduced"><i class="fa fa-check"></i><b>11.1</b> ggplot2 introduced</a></li>
<li class="chapter" data-level="11.2" data-path="graphics-with-ggplot2.html"><a href="graphics-with-ggplot2.html#scaling-axes-and-varying-colour-or-shapes-by-factor-levels"><i class="fa fa-check"></i><b>11.2</b> Scaling axes and varying colour or shapes by factor levels</a></li>
<li class="chapter" data-level="11.3" data-path="graphics-with-ggplot2.html"><a href="graphics-with-ggplot2.html#facets"><i class="fa fa-check"></i><b>11.3</b> Facets</a></li>
<li class="chapter" data-level="11.4" data-path="graphics-with-ggplot2.html"><a href="graphics-with-ggplot2.html#histograms"><i class="fa fa-check"></i><b>11.4</b> Histograms</a></li>
<li class="chapter" data-level="11.5" data-path="graphics-with-ggplot2.html"><a href="graphics-with-ggplot2.html#boxplots-1"><i class="fa fa-check"></i><b>11.5</b> Boxplots</a></li>
<li class="chapter" data-level="11.6" data-path="graphics-with-ggplot2.html"><a href="graphics-with-ggplot2.html#final-word"><i class="fa fa-check"></i><b>11.6</b> Final word</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="basic-statistical-concepts.html"><a href="basic-statistical-concepts.html"><i class="fa fa-check"></i><b>12</b> Basic Statistical Concepts</a><ul>
<li class="chapter" data-level="12.1" data-path="basic-statistical-concepts.html"><a href="basic-statistical-concepts.html#populations-and-samples"><i class="fa fa-check"></i><b>12.1</b> Populations and Samples</a></li>
<li class="chapter" data-level="12.2" data-path="basic-statistical-concepts.html"><a href="basic-statistical-concepts.html#descriptive-and-exploratory-statistics"><i class="fa fa-check"></i><b>12.2</b> Descriptive and exploratory statistics</a><ul>
<li class="chapter" data-level="12.2.1" data-path="basic-statistical-concepts.html"><a href="basic-statistical-concepts.html#maximum-and-minimum"><i class="fa fa-check"></i><b>12.2.1</b> Maximum and minimum</a></li>
<li class="chapter" data-level="12.2.2" data-path="basic-statistical-concepts.html"><a href="basic-statistical-concepts.html#frequency-distribution"><i class="fa fa-check"></i><b>12.2.2</b> Frequency distribution</a></li>
<li class="chapter" data-level="12.2.3" data-path="basic-statistical-concepts.html"><a href="basic-statistical-concepts.html#kinds-of-frequency-distribution"><i class="fa fa-check"></i><b>12.2.3</b> Kinds of frequency distribution</a></li>
<li class="chapter" data-level="12.2.4" data-path="basic-statistical-concepts.html"><a href="basic-statistical-concepts.html#measures-of-central-tendency"><i class="fa fa-check"></i><b>12.2.4</b> Measures of central tendency</a></li>
<li class="chapter" data-level="12.2.5" data-path="basic-statistical-concepts.html"><a href="basic-statistical-concepts.html#measures-of-dispersion"><i class="fa fa-check"></i><b>12.2.5</b> Measures of dispersion</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="basic-statistical-concepts.html"><a href="basic-statistical-concepts.html#standard-errors-and-confidence-intervals"><i class="fa fa-check"></i><b>12.3</b> Standard errors and confidence intervals</a><ul>
<li class="chapter" data-level="12.3.1" data-path="basic-statistical-concepts.html"><a href="basic-statistical-concepts.html#code-used-to-draw-figure-6"><i class="fa fa-check"></i><b>12.3.1</b> Code used to draw figure 6</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="what-is-statistical-testing.html"><a href="what-is-statistical-testing.html"><i class="fa fa-check"></i><b>13</b> What is statistical testing?</a><ul>
<li class="chapter" data-level="13.1" data-path="what-is-statistical-testing.html"><a href="what-is-statistical-testing.html#the-problem"><i class="fa fa-check"></i><b>13.1</b> The problem</a></li>
<li class="chapter" data-level="13.2" data-path="what-is-statistical-testing.html"><a href="what-is-statistical-testing.html#statistical-testing-in-a-nutshell"><i class="fa fa-check"></i><b>13.2</b> Statistical testing in a nutshell</a><ul>
<li class="chapter" data-level="13.2.1" data-path="what-is-statistical-testing.html"><a href="what-is-statistical-testing.html#decide-on-the-null-and-alternative-hypotheses."><i class="fa fa-check"></i><b>13.2.1</b> Decide on the null and alternative hypotheses.</a></li>
<li class="chapter" data-level="13.2.2" data-path="what-is-statistical-testing.html"><a href="what-is-statistical-testing.html#calculate-the-size-of-the-effect."><i class="fa fa-check"></i><b>13.2.2</b> Calculate the size of the effect.</a></li>
<li class="chapter" data-level="13.2.3" data-path="what-is-statistical-testing.html"><a href="what-is-statistical-testing.html#transform-the-effect-size-so-that-we-can-compare-it-to-an-expected-distribution."><i class="fa fa-check"></i><b>13.2.3</b> Transform the effect size so that we can compare it to an expected distribution.</a></li>
<li class="chapter" data-level="13.2.4" data-path="what-is-statistical-testing.html"><a href="what-is-statistical-testing.html#ask-what-the-probability-is-of-observing-an-effect-as-big-or-bigger-than-the-one-we-have-seen-assuming-the-null-hypothesis-to-be-true."><i class="fa fa-check"></i><b>13.2.4</b> Ask what the probability is of observing an effect as big, or bigger than the one we have seen, assuming the null hypothesis to be true.</a></li>
<li class="chapter" data-level="13.2.5" data-path="what-is-statistical-testing.html"><a href="what-is-statistical-testing.html#think-about-what-the-result-means."><i class="fa fa-check"></i><b>13.2.5</b> Think about what the result means.</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="what-is-statistical-testing.html"><a href="what-is-statistical-testing.html#how-a-statistical-test-works"><i class="fa fa-check"></i><b>13.3</b> How a statistical test works</a><ul>
<li class="chapter" data-level="13.3.1" data-path="what-is-statistical-testing.html"><a href="what-is-statistical-testing.html#step-1-generating-our-null-and-alternative-hypotheses."><i class="fa fa-check"></i><b>13.3.1</b> Step 1 generating our null and alternative hypotheses.</a></li>
<li class="chapter" data-level="13.3.2" data-path="what-is-statistical-testing.html"><a href="what-is-statistical-testing.html#step-2-calculating-the-size-of-the-effect"><i class="fa fa-check"></i><b>13.3.2</b> Step 2 calculating the size of the effect</a></li>
<li class="chapter" data-level="13.3.3" data-path="what-is-statistical-testing.html"><a href="what-is-statistical-testing.html#step-3-transforming-the-effect-size-so-that-we-can-compare-it-to-an-expected-distribution."><i class="fa fa-check"></i><b>13.3.3</b> Step 3 Transforming the effect size so that we can compare it to an expected distribution.</a></li>
<li class="chapter" data-level="13.3.4" data-path="what-is-statistical-testing.html"><a href="what-is-statistical-testing.html#step-4-what-is-the-probability-is-of-observing-an-effect-as-big-or-bigger-than-the-one-we-have-seen-assuming-the-null-hypothesis-to-be-true"><i class="fa fa-check"></i><b>13.3.4</b> Step 4 What is the probability is of observing an effect as big, or bigger than the one we have seen, assuming the null hypothesis to be true?</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="what-is-statistical-testing.html"><a href="what-is-statistical-testing.html#what-statistical-testing-does-and-doesnt-tell-us"><i class="fa fa-check"></i><b>13.4</b> What statistical testing does and doesn’t tell us</a></li>
<li class="chapter" data-level="13.5" data-path="what-is-statistical-testing.html"><a href="what-is-statistical-testing.html#code-used-to-draw-figure-5"><i class="fa fa-check"></i><b>13.5</b> Code used to draw figure 5</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="the-chi-squared-test-and-a-classic-dataset-on-smoking-and-cancer.html"><a href="the-chi-squared-test-and-a-classic-dataset-on-smoking-and-cancer.html"><i class="fa fa-check"></i><b>14</b> The Chi-squared Test and a Classic Dataset on Smoking and Cancer</a><ul>
<li class="chapter" data-level="14.1" data-path="the-chi-squared-test-and-a-classic-dataset-on-smoking-and-cancer.html"><a href="the-chi-squared-test-and-a-classic-dataset-on-smoking-and-cancer.html#are-lung-cancer-patients-who-smoke-more-likely-to-be-heavy-smokers"><i class="fa fa-check"></i><b>14.1</b> Are lung cancer patients who smoke more likely to be heavy smokers?</a></li>
<li class="chapter" data-level="14.2" data-path="the-chi-squared-test-and-a-classic-dataset-on-smoking-and-cancer.html"><a href="the-chi-squared-test-and-a-classic-dataset-on-smoking-and-cancer.html#the-chi-squared-test"><i class="fa fa-check"></i><b>14.2</b> The Chi-squared test</a></li>
<li class="chapter" data-level="14.3" data-path="the-chi-squared-test-and-a-classic-dataset-on-smoking-and-cancer.html"><a href="the-chi-squared-test-and-a-classic-dataset-on-smoking-and-cancer.html#chi-squared-test-with-contingency-tables"><i class="fa fa-check"></i><b>14.3</b> Chi-squared test with contingency tables</a></li>
<li class="chapter" data-level="14.4" data-path="the-chi-squared-test-and-a-classic-dataset-on-smoking-and-cancer.html"><a href="the-chi-squared-test-and-a-classic-dataset-on-smoking-and-cancer.html#assumptions-and-limitations-of-the-chi-squared-test"><i class="fa fa-check"></i><b>14.4</b> Assumptions and limitations of the chi-squared test</a></li>
<li class="chapter" data-level="14.5" data-path="the-chi-squared-test-and-a-classic-dataset-on-smoking-and-cancer.html"><a href="the-chi-squared-test-and-a-classic-dataset-on-smoking-and-cancer.html#are-lung-cancer-patients-more-likely-to-be-smokers-than-controls"><i class="fa fa-check"></i><b>14.5</b> Are lung cancer patients more likely to be smokers than controls?</a></li>
<li class="chapter" data-level="14.6" data-path="the-chi-squared-test-and-a-classic-dataset-on-smoking-and-cancer.html"><a href="the-chi-squared-test-and-a-classic-dataset-on-smoking-and-cancer.html#fishers-exact-test"><i class="fa fa-check"></i><b>14.6</b> Fisher’s exact test</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="comparing-immune-responses-between-two-caterpillar-species-using-a-t-test.html"><a href="comparing-immune-responses-between-two-caterpillar-species-using-a-t-test.html"><i class="fa fa-check"></i><b>15</b> Comparing immune responses between two caterpillar species using a t-test</a><ul>
<li class="chapter" data-level="15.1" data-path="comparing-immune-responses-between-two-caterpillar-species-using-a-t-test.html"><a href="comparing-immune-responses-between-two-caterpillar-species-using-a-t-test.html#assumptions-and-limitations-of-standard-parametric-statistics"><i class="fa fa-check"></i><b>15.1</b> Assumptions and limitations of standard parametric statistics</a><ul>
<li class="chapter" data-level="15.1.1" data-path="comparing-immune-responses-between-two-caterpillar-species-using-a-t-test.html"><a href="comparing-immune-responses-between-two-caterpillar-species-using-a-t-test.html#normal-errors."><i class="fa fa-check"></i><b>15.1.1</b> Normal errors.</a></li>
<li class="chapter" data-level="15.1.2" data-path="comparing-immune-responses-between-two-caterpillar-species-using-a-t-test.html"><a href="comparing-immune-responses-between-two-caterpillar-species-using-a-t-test.html#independence-of-data-points."><i class="fa fa-check"></i><b>15.1.2</b> Independence of data points.</a></li>
<li class="chapter" data-level="15.1.3" data-path="comparing-immune-responses-between-two-caterpillar-species-using-a-t-test.html"><a href="comparing-immune-responses-between-two-caterpillar-species-using-a-t-test.html#equal-variances."><i class="fa fa-check"></i><b>15.1.3</b> Equal variances.</a></li>
</ul></li>
<li class="chapter" data-level="15.2" data-path="comparing-immune-responses-between-two-caterpillar-species-using-a-t-test.html"><a href="comparing-immune-responses-between-two-caterpillar-species-using-a-t-test.html#importing-the-data"><i class="fa fa-check"></i><b>15.2</b> Importing the Data</a></li>
<li class="chapter" data-level="15.3" data-path="comparing-immune-responses-between-two-caterpillar-species-using-a-t-test.html"><a href="comparing-immune-responses-between-two-caterpillar-species-using-a-t-test.html#descriptives-and-initial-exploration"><i class="fa fa-check"></i><b>15.3</b> Descriptives and Initial Exploration</a></li>
<li class="chapter" data-level="15.4" data-path="comparing-immune-responses-between-two-caterpillar-species-using-a-t-test.html"><a href="comparing-immune-responses-between-two-caterpillar-species-using-a-t-test.html#comparing-two-means-with-a-t-test"><i class="fa fa-check"></i><b>15.4</b> Comparing Two Means With a t-test</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="correlation-analysis.html"><a href="correlation-analysis.html"><i class="fa fa-check"></i><b>16</b> Correlation analysis</a><ul>
<li class="chapter" data-level="16.1" data-path="correlation-analysis.html"><a href="correlation-analysis.html#calculating-the-correlation-coefficient"><i class="fa fa-check"></i><b>16.1</b> Calculating the correlation coefficient</a><ul>
<li class="chapter" data-level="16.1.1" data-path="correlation-analysis.html"><a href="correlation-analysis.html#interpreting-our-correlation-coefficient."><i class="fa fa-check"></i><b>16.1.1</b> Interpreting our correlation coefficient.</a></li>
</ul></li>
<li class="chapter" data-level="16.2" data-path="correlation-analysis.html"><a href="correlation-analysis.html#statistical-significance-of-r"><i class="fa fa-check"></i><b>16.2</b> Statistical significance of <em>r</em></a></li>
<li class="chapter" data-level="16.3" data-path="correlation-analysis.html"><a href="correlation-analysis.html#assumptions-of-correlation-analysis"><i class="fa fa-check"></i><b>16.3</b> Assumptions of correlation analysis</a><ul>
<li class="chapter" data-level="16.3.1" data-path="correlation-analysis.html"><a href="correlation-analysis.html#comparing-correlations-between-swim-run-and-bike-splits"><i class="fa fa-check"></i><b>16.3.1</b> Comparing correlations between swim, run and bike splits</a></li>
</ul></li>
<li class="chapter" data-level="16.4" data-path="correlation-analysis.html"><a href="correlation-analysis.html#correlation-causality-sample-size-and-significance."><i class="fa fa-check"></i><b>16.4</b> Correlation, causality, sample size and significance.</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="using-linear-regression-to-analyse-tb-trends-in-the-uk.html"><a href="using-linear-regression-to-analyse-tb-trends-in-the-uk.html"><i class="fa fa-check"></i><b>17</b> Using Linear Regression to Analyse TB trends in the UK</a><ul>
<li class="chapter" data-level="17.0.1" data-path="using-linear-regression-to-analyse-tb-trends-in-the-uk.html"><a href="using-linear-regression-to-analyse-tb-trends-in-the-uk.html#least-squares-line-fitting"><i class="fa fa-check"></i><b>17.0.1</b> Least squares line fitting</a></li>
<li class="chapter" data-level="17.0.2" data-path="using-linear-regression-to-analyse-tb-trends-in-the-uk.html"><a href="using-linear-regression-to-analyse-tb-trends-in-the-uk.html#significance-tests-for-linear-regression"><i class="fa fa-check"></i><b>17.0.2</b> Significance tests for linear regression</a></li>
<li class="chapter" data-level="17.1" data-path="using-linear-regression-to-analyse-tb-trends-in-the-uk.html"><a href="using-linear-regression-to-analyse-tb-trends-in-the-uk.html#bovine-tb"><i class="fa fa-check"></i><b>17.1</b> Bovine TB</a></li>
<li class="chapter" data-level="17.2" data-path="using-linear-regression-to-analyse-tb-trends-in-the-uk.html"><a href="using-linear-regression-to-analyse-tb-trends-in-the-uk.html#assumptions-of-linear-regression"><i class="fa fa-check"></i><b>17.2</b> Assumptions of linear regression</a><ul>
<li class="chapter" data-level="17.2.1" data-path="using-linear-regression-to-analyse-tb-trends-in-the-uk.html"><a href="using-linear-regression-to-analyse-tb-trends-in-the-uk.html#diagnostic-plots"><i class="fa fa-check"></i><b>17.2.1</b> Diagnostic plots</a></li>
<li class="chapter" data-level="17.2.2" data-path="using-linear-regression-to-analyse-tb-trends-in-the-uk.html"><a href="using-linear-regression-to-analyse-tb-trends-in-the-uk.html#diagnostic-plots-for-our-m.bovis-regression"><i class="fa fa-check"></i><b>17.2.2</b> Diagnostic plots for our <em>M.bovis</em> regression</a></li>
</ul></li>
<li class="chapter" data-level="17.3" data-path="using-linear-regression-to-analyse-tb-trends-in-the-uk.html"><a href="using-linear-regression-to-analyse-tb-trends-in-the-uk.html#interpreting-our-regression-and-predicting-future-cases"><i class="fa fa-check"></i><b>17.3</b> Interpreting our regression and predicting future cases</a></li>
<li class="chapter" data-level="17.4" data-path="using-linear-regression-to-analyse-tb-trends-in-the-uk.html"><a href="using-linear-regression-to-analyse-tb-trends-in-the-uk.html#multi-drug-resistant-tb"><i class="fa fa-check"></i><b>17.4</b> Multi-drug resistant TB</a></li>
<li class="chapter" data-level="17.5" data-path="using-linear-regression-to-analyse-tb-trends-in-the-uk.html"><a href="using-linear-regression-to-analyse-tb-trends-in-the-uk.html#fitting-a-quadratic-model"><i class="fa fa-check"></i><b>17.5</b> Fitting a quadratic model</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="anova-and-football.html"><a href="anova-and-football.html"><i class="fa fa-check"></i><b>18</b> ANOVA and Football</a><ul>
<li class="chapter" data-level="18.1" data-path="anova-and-football.html"><a href="anova-and-football.html#analysis-of-variance"><i class="fa fa-check"></i><b>18.1</b> Analysis of Variance</a></li>
<li class="chapter" data-level="18.2" data-path="anova-and-football.html"><a href="anova-and-football.html#interpreting-anova-results"><i class="fa fa-check"></i><b>18.2</b> Interpreting ANOVA results</a></li>
<li class="chapter" data-level="18.3" data-path="anova-and-football.html"><a href="anova-and-football.html#what-makes-a-professional-footballer"><i class="fa fa-check"></i><b>18.3</b> What makes a professional footballer?</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="yeast-sex-and-two-factor-anova-.html"><a href="yeast-sex-and-two-factor-anova-.html"><i class="fa fa-check"></i><b>19</b> Yeast sex and two factor ANOVA.</a><ul>
<li class="chapter" data-level="19.1" data-path="yeast-sex-and-two-factor-anova-.html"><a href="yeast-sex-and-two-factor-anova-.html#yeast-sexual-selection"><i class="fa fa-check"></i><b>19.1</b> Yeast sexual selection</a></li>
<li class="chapter" data-level="19.2" data-path="yeast-sex-and-two-factor-anova-.html"><a href="yeast-sex-and-two-factor-anova-.html#understanding-the-coefficients-table"><i class="fa fa-check"></i><b>19.2</b> Understanding the coefficients table</a></li>
<li class="chapter" data-level="19.3" data-path="yeast-sex-and-two-factor-anova-.html"><a href="yeast-sex-and-two-factor-anova-.html#which-statistical-tests-to-use-with-lm"><i class="fa fa-check"></i><b>19.3</b> Which statistical tests to use with <code>lm()</code>?</a></li>
<li class="chapter" data-level="19.4" data-path="yeast-sex-and-two-factor-anova-.html"><a href="yeast-sex-and-two-factor-anova-.html#diagnostics"><i class="fa fa-check"></i><b>19.4</b> Diagnostics</a></li>
<li class="chapter" data-level="19.5" data-path="yeast-sex-and-two-factor-anova-.html"><a href="yeast-sex-and-two-factor-anova-.html#visualising-the-data"><i class="fa fa-check"></i><b>19.5</b> Visualising the data</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introductory R: A beginner’s guide to programming, data visualisation and statistical analysis in R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="what-is-statistical-testing" class="section level1">
<h1><span class="header-section-number">Chapter 13</span> What is statistical testing?</h1>
<p>Some readers will already know a reasonable amount of statistics and understand what we mean by a statistical test and know what statistical significance is. Even experienced scientists who have an approximate understanding of what a p-value is often end up making serious errors in their interpretation, however, so if your understanding of statistical testing is even slightly wooly, and especially if you’re a bit lost as to what statistical testing is, or if you don’t really know what a p-value represents, then it’s probably a good idea to read through this section.</p>
<div id="the-problem" class="section level2">
<h2><span class="header-section-number">13.1</span> The problem</h2>
<p>The fundamental problem that statistical testing is designed to address is that when we are doing science we usually have to <em>sample</em> from a <em>population</em> — in other words we select some individuals, or some events, to measure from the total number available, and we hope that what we have got in our sample is representative of the actual population. In the case of the Doll and Hill cancer research that we will look at in the next chapter the investigators took a sample of patients presenting with lung cancer that was restricted to certain hospitals in London over a few years, in the hope that conclusions drawn from this sample of patients would be applicable to lung cancer patients generally. In this example we know now that the conclusions that were drawn were indeed important and general, but there is a risk when we are only measuring some members of a population that the individuals chosen for the sample will <em>not</em> be representative of the total population. This can arise if the way the sample is chosen means that we only get a specific subset of the population: for the Doll and Hill study, for example, there was a possibility that lung cancer patients in London are in some way different from other lung cancer patients in other parts of the world, and this could have made the results of the study less generally applicable. This is why scientists nowadays take care to avoid any sort of bias in their samples and to select the individuals in their samples at random. Nonetheless, even when we have a properly randomised sample we can still end up with one that’s not representative: it could have simply been the case that Doll and Hill happened to have a few more lung cancer patients who were heavy smokers (or patients without lung cancer who were light smokers) by pure random chance, which is why they saw the pattern that they did. Statistical testing aims to tell us the probability that the patterns that we see in the data could have arisen, assuming nothing but this random chance produced them.</p>
<p>Let’s take a look at an example. Assume we’ve measured the diameter of a patch of red colouration of the dewlaps of ten male lizards, then treated each one with an implant which will give them a raised level of testosterone, and then measured the diameter of the red patch on their dewlaps again after a week. We know that the red patches are used in sexual signalling, so we are trying to test the hypothesis that patch size is influenced by testosterone. Here are our data, with patch sizes in mm:</p>
<div class="sourceCode" id="cb395"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb395-1"><a href="what-is-statistical-testing.html#cb395-1"></a>patch.before &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="fl">12.3</span>, <span class="fl">9.0</span>, <span class="fl">11.5</span>, <span class="fl">11.9</span>, <span class="fl">14.2</span>, <span class="fl">8.7</span>, <span class="fl">10.5</span>, <span class="fl">9.2</span>, <span class="fl">12.9</span>, <span class="fl">10.1</span>)</span>
<span id="cb395-2"><a href="what-is-statistical-testing.html#cb395-2"></a>patch.after &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="fl">12.3</span>, <span class="fl">10.0</span>, <span class="fl">10.8</span>, <span class="fl">13.8</span>, <span class="fl">14.1</span>, <span class="fl">10.5</span>, <span class="fl">9.1</span>, <span class="fl">12.2</span>, <span class="fl">13.7</span>, <span class="fl">10.3</span>)</span></code></pre></div>
<p>This experiment is a <em>paired design</em>, meaning that we have pairs of measurements taken on the same individual. Because of this we are not so interested in the absolute size of each patch as we are in the differences in size for each lizard before and after treatment. If testosterone is controlling patch size then we might predict that patch size after treatment should be greater than patch size before treatment. Each lizard is recorded at the same place in each vector so we can calculate the differences by just subtracting one from the other.</p>
<div class="sourceCode" id="cb396"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb396-1"><a href="what-is-statistical-testing.html#cb396-1"></a>patch.diff &lt;-<span class="st"> </span>patch.after <span class="op">-</span><span class="st"> </span>patch.before</span>
<span id="cb396-2"><a href="what-is-statistical-testing.html#cb396-2"></a>patch.diff</span>
<span id="cb396-3"><a href="what-is-statistical-testing.html#cb396-3"></a> [<span class="dv">1</span>]  <span class="fl">0.0</span>  <span class="fl">1.0</span> <span class="fl">-0.7</span>  <span class="fl">1.9</span> <span class="fl">-0.1</span>  <span class="fl">1.8</span> <span class="fl">-1.4</span>  <span class="fl">3.0</span>  <span class="fl">0.8</span>  <span class="fl">0.2</span></span></code></pre></div>
<p>Some patches have got bigger, some have got smaller and some have stayed the same size. What’s the average change in patch size?</p>
<div class="sourceCode" id="cb397"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb397-1"><a href="what-is-statistical-testing.html#cb397-1"></a><span class="kw">mean</span>(patch.diff)</span>
<span id="cb397-2"><a href="what-is-statistical-testing.html#cb397-2"></a>[<span class="dv">1</span>] <span class="fl">0.65</span></span></code></pre></div>
<p>The average difference in patch size is 0.65mm. Not huge, but certainly positive, which is what we would have predicted. The problem arises when we ask the question of whether what we’re seeing is just a chance event — we might have happened to get a few more lizards in our sample who grew bigger patches simply by accident. To get an idea of how likely this is, we can look at what happens if we sample at random from two populations that are the same and then calculate a difference. R has the handy <code>rnorm()</code> function that will produce random numbers drawn from a normal distribution (technically these are pseudorandom numbers but for our purposes just think of them as random). We can use <code>replicate()</code> to generate a large number of samples, and then we can use <code>apply()</code> to calculate the difference between pairs of samples as follows. We can use the mean and standard deviation of first set of meaurements to define the normal distribution that we want our samples to be drawn from. The <code>hist()</code> function will draw a histogram showing the frequency distribution of our random samples.</p>
<div class="sourceCode" id="cb398"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb398-1"><a href="what-is-statistical-testing.html#cb398-1"></a></span>
<span id="cb398-2"><a href="what-is-statistical-testing.html#cb398-2"></a><span class="co"># Generate two matrices of data, each with 1000 rows and 10 columns, with the data being drawn at random from a normal distribution with mean and sd = the mean and sd of our lizard&#39;s patches before treatment</span></span>
<span id="cb398-3"><a href="what-is-statistical-testing.html#cb398-3"></a>data1 &lt;-<span class="st"> </span><span class="kw">replicate</span>(<span class="dv">1000</span>, <span class="kw">rnorm</span>(<span class="dv">10</span>, <span class="kw">mean</span>(patch.before), <span class="kw">sd</span>(patch.before)))</span>
<span id="cb398-4"><a href="what-is-statistical-testing.html#cb398-4"></a>data2 &lt;-<span class="st"> </span><span class="kw">replicate</span>(<span class="dv">1000</span>, <span class="kw">rnorm</span>(<span class="dv">10</span>, <span class="kw">mean</span>(patch.before), <span class="kw">sd</span>(patch.before)))</span>
<span id="cb398-5"><a href="what-is-statistical-testing.html#cb398-5"></a></span>
<span id="cb398-6"><a href="what-is-statistical-testing.html#cb398-6"></a><span class="co"># Calculate the mean for each row and subtract the means for the second matrix from those of the first</span></span>
<span id="cb398-7"><a href="what-is-statistical-testing.html#cb398-7"></a>mean.differences10 &lt;-<span class="st"> </span><span class="kw">apply</span>(data1, <span class="dv">2</span>, mean) <span class="op">-</span><span class="st"> </span><span class="kw">apply</span>(data2, <span class="dv">2</span>, mean)</span>
<span id="cb398-8"><a href="what-is-statistical-testing.html#cb398-8"></a></span>
<span id="cb398-9"><a href="what-is-statistical-testing.html#cb398-9"></a><span class="co"># Plot a histogram of the differences</span></span>
<span id="cb398-10"><a href="what-is-statistical-testing.html#cb398-10"></a><span class="kw">hist</span>(</span>
<span id="cb398-11"><a href="what-is-statistical-testing.html#cb398-11"></a>  mean.differences10,</span>
<span id="cb398-12"><a href="what-is-statistical-testing.html#cb398-12"></a>  <span class="dt">breaks =</span> <span class="dv">20</span>,</span>
<span id="cb398-13"><a href="what-is-statistical-testing.html#cb398-13"></a>  <span class="dt">col =</span> <span class="st">&quot;grey&quot;</span>,</span>
<span id="cb398-14"><a href="what-is-statistical-testing.html#cb398-14"></a>  <span class="dt">xlab =</span> <span class="st">&quot;Mean&quot;</span>,</span>
<span id="cb398-15"><a href="what-is-statistical-testing.html#cb398-15"></a>  <span class="dt">main =</span> <span class="st">&quot;&quot;</span>,</span>
<span id="cb398-16"><a href="what-is-statistical-testing.html#cb398-16"></a>  <span class="dt">font.lab =</span> <span class="dv">2</span></span>
<span id="cb398-17"><a href="what-is-statistical-testing.html#cb398-17"></a>)</span>
<span id="cb398-18"><a href="what-is-statistical-testing.html#cb398-18"></a></span>
<span id="cb398-19"><a href="what-is-statistical-testing.html#cb398-19"></a><span class="co"># Add a vertical line</span></span>
<span id="cb398-20"><a href="what-is-statistical-testing.html#cb398-20"></a><span class="kw">abline</span>(<span class="dt">v =</span> <span class="fl">0.65</span>, <span class="dt">lty =</span> <span class="dv">2</span>)</span></code></pre></div>
<p>The “breaks” in the <code>hist()</code> function argument makes R draw our histogram with the data separated into rather more intervals than it would normally use, the “col=grey” argument fills in the bars and “xlab=”“Mean” labels the x-axis. The <code>abline()</code> function draws in a vertical line at 0.65, which is the value of the mean difference for our sample.</p>
<div class="figure"><span id="fig:test1"></span>
<img src="3rd_Edition_files/figure-html/test1-1.png" alt="Histogram showing the differences between two sets
 of 1000 randomly generated data sets." width="672" />
<p class="caption">
Figure 13.1: Histogram showing the differences between two sets
of 1000 randomly generated data sets.
</p>
</div>
<p>Just by looking at the histogram you can see that although the most common value for the differences between our samples is zero or close to it there are a substantial number of means that are rather different from zero. We can ask R to count the number of differences that are greater than 0.65 for us:</p>
<div class="sourceCode" id="cb399"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb399-1"><a href="what-is-statistical-testing.html#cb399-1"></a><span class="kw">sum</span>(mean.differences10<span class="op">&gt;</span><span class="fl">0.65</span>)</span></code></pre></div>
<p>Let’s break that down. <code>mean.differences10&gt;0.65</code> will go through the 1000 numbers saved in mean.differences10 and decide whether the value of each is greater than 0.65, and if it is it will return a value of TRUE, and if it is not then it will return a value of FALSE. sum() will work on a vector of logical values (in other words, a string of TRUE or FALSE values) as though TRUE is equal to 1 and FALSE is equal to zero.</p>
<div class="sourceCode" id="cb400"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb400-1"><a href="what-is-statistical-testing.html#cb400-1"></a><span class="kw">sum</span>(mean.differences10<span class="op">&gt;</span><span class="fl">0.65</span>)</span>
<span id="cb400-2"><a href="what-is-statistical-testing.html#cb400-2"></a>[<span class="dv">1</span>] <span class="dv">222</span></span></code></pre></div>
<p>When we sample from two identical populations, therefore, we see a difference as big as, or bigger than, the difference that we’ve observed somewhere between a fifth and a quarter of the time. This means that we are very limited in the inference we can draw from our lizard data — since there’s a good chance that a difference as large (or larger) than the one we found would occur, even if the size of the patches after treatment was simply a random sample centred around the initial values. This makes is difficult to draw any meaningful conclusions from these data.</p>
<p>This is the basis of statistical hypothesis testing. <strong>What a statistical hypothesis test does is to calculate the probability of observing the data, assuming that there is no difference between the populations the data were drawn from.</strong> Most traditional statistical analyses don’t use a simulation to work out how often we might expect to see the observed data, as we have just done. Instead they calculate a standardised version of the observed effect and then compare that with the known statistical distribution that it should follow if there really were no difference or no effect.</p>
</div>
<div id="statistical-testing-in-a-nutshell" class="section level2">
<h2><span class="header-section-number">13.2</span> Statistical testing in a nutshell</h2>
<p>The process of statistical testing can be a bit hard to swallow if you try to eat it all in one go, but we can break it down into a series of easily chewable mouthfuls.</p>
<div id="decide-on-the-null-and-alternative-hypotheses." class="section level3">
<h3><span class="header-section-number">13.2.1</span> Decide on the null and alternative hypotheses.</h3>
<p>These are two mutually exclusive explanations for the patterns that we see in the data. The <em>null hypothesis</em> is usually the hypothesis that there is no effect — that there is no difference between two means, for example, or that the true slope of a relationship between two variables is equal to zero. The <em>alternative hypothesis</em> in these two cases would be that there is a difference between the means, or that the slope of the relationship is not equal to zero. It’s important to remember that the null hypothesis doesn’t have to be “no effect”, and that theory can often dictate other nulls. As an example, there are good reasons to expect that the slope of the relationship between log body size and log metabolic rate (the allometric slope) should be 3/4 (“Kleiber’s law”), and in a study of whether body size and deviate from this relationship rate it might be best to use the null hypothesis that the slope of the relationship is equal to 3/4, and the alternative hypothesis that the slope is not equal to 3/4. In general, it’s good practice to think carefully about your choice of null and alternative hypotheses and to avoid the use of “silly nulls” which are impossible or very unlikely to be true.</p>
</div>
<div id="calculate-the-size-of-the-effect." class="section level3">
<h3><span class="header-section-number">13.2.2</span> Calculate the size of the effect.</h3>
<p>Here we ask what the magnitude of the actual effect that we’ve observed is: we calculate the difference between means, or the slope of the relationship between our two variables, or the difference in intercept between our treatments, or whatever other measure is dictated by our study.</p>
</div>
<div id="transform-the-effect-size-so-that-we-can-compare-it-to-an-expected-distribution." class="section level3">
<h3><span class="header-section-number">13.2.3</span> Transform the effect size so that we can compare it to an expected distribution.</h3>
<p>This is where things can get a bit obscure. We want to know what the probability of seeing an effect as large as, or larger than, the one we’ve observed is, given that the null hypothesis is true. Usually we can’t calculate this from the straightforward size of the effect, but we can often carry out a mathematical transformation that will make our effect size directly comparable to a known distribution of effect sizes. This can sometimes simply mean standardising it by dividing by the standard deviation, and it can sometimes be more complex.</p>
</div>
<div id="ask-what-the-probability-is-of-observing-an-effect-as-big-or-bigger-than-the-one-we-have-seen-assuming-the-null-hypothesis-to-be-true." class="section level3">
<h3><span class="header-section-number">13.2.4</span> Ask what the probability is of observing an effect as big, or bigger than the one we have seen, assuming the null hypothesis to be true.</h3>
<p>Having worked out our effect size and carried out a transformation on it to make it comparable to a known distribution, we can calculate the probability of observing it if the null hypothesis were true. As you probably know, if that probability is less than 0.05 then by convention we reject the null hypothesis as being unlikely “at the 5% level”, and tentatively accept the alternative hypothesis: in other words if p&lt;0.05 we would say that we have a statistically significant difference between our means, or a slope that is signficantly different from zero.</p>
</div>
<div id="think-about-what-the-result-means." class="section level3">
<h3><span class="header-section-number">13.2.5</span> Think about what the result means.</h3>
<p>This is the bit that people sometimes miss out, but it’s the most important part of the whole process. Have a look at the section on “What statistical testing does and doesn’t tell us” at the end of the chapter for more on this.</p>
</div>
</div>
<div id="how-a-statistical-test-works" class="section level2">
<h2><span class="header-section-number">13.3</span> How a statistical test works</h2>
<p>Let’s illustrate this process with a look at another lizard example. If you know a bit about experimental design you’ll probably have raised an eyebrow at the study described above. There are lots of reasons why the size of a sexual ornament might change over time, and added testosterone is only one of them. It could be, for example, that we caught our lizards at the end of the breeding season when their ornamentation was likely to shrink, so any increases from our testosterone treatment would be cancelled out. It could be that the surgery to add the testosterone implant affects their condition with potential knock-on effects on the size of the ornament. If you think about it there are an almost infinite number of reasons why the colour patch on our lizards dewlaps might shrink or grow over time which might interfere with our ability to detect an effect of testosterone. What this study needs in order to make it science rather than pointless lizard-abuse is a control - a second set of lizards which had an implant, but one without testosterone. This is a “procedural control”, meaning that the animals in question experienced the procedure but did not get the specific treatment that we’re interested in. If we were doing this study for real we would probably want a second set of control lizards that didn’t get the implant at all - this would allow us to measure the effect of the implant as well as the effect of the testosterone, but since this is a made-up example<a href="#fn15" class="footnote-ref" id="fnref15"><sup>15</sup></a> we can stick with the procedural controls.</p>
<p>Here are the differences in patch size for our procedural control lizards:</p>
<div class="sourceCode" id="cb401"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb401-1"><a href="what-is-statistical-testing.html#cb401-1"></a>patch.diff.control&lt;-<span class="kw">c</span>(<span class="op">-</span><span class="fl">0.7</span>,<span class="op">-</span><span class="fl">1.46</span>,<span class="op">-</span><span class="fl">0.3</span>,<span class="op">-</span><span class="fl">3.7</span>,<span class="fl">0.2</span>,<span class="fl">1.2</span>,<span class="op">-</span><span class="fl">3.6</span>,<span class="op">-</span><span class="fl">2.1</span>,<span class="op">-</span><span class="fl">0.3</span>,<span class="op">-</span><span class="fl">1.1</span>)</span></code></pre></div>
<p>That looks like a rather different result to our testosterone treated lizards. Whereas most (7 out of 10) of the lizards with the testosterone implants had ornaments that either got bigger or stayed the same over the course of the study, 7 out of the 10 control lizards had ornaments that got smaller. Since we only have 10 individuals per group we can visualise the difference between the two groups with a strip chart.</p>
<div class="sourceCode" id="cb402"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb402-1"><a href="what-is-statistical-testing.html#cb402-1"></a></span>
<span id="cb402-2"><a href="what-is-statistical-testing.html#cb402-2"></a><span class="kw">stripchart</span>(</span>
<span id="cb402-3"><a href="what-is-statistical-testing.html#cb402-3"></a>  <span class="dt">x =</span> <span class="kw">list</span>(patch.diff, patch.diff.control),</span>
<span id="cb402-4"><a href="what-is-statistical-testing.html#cb402-4"></a>  <span class="dt">cex =</span> <span class="fl">1.5</span>,</span>
<span id="cb402-5"><a href="what-is-statistical-testing.html#cb402-5"></a>  <span class="dt">pch =</span> <span class="dv">1</span>,</span>
<span id="cb402-6"><a href="what-is-statistical-testing.html#cb402-6"></a>  <span class="dt">ylab =</span> <span class="st">&quot;Change in ornament size (mm)&quot;</span>,</span>
<span id="cb402-7"><a href="what-is-statistical-testing.html#cb402-7"></a>  <span class="dt">vertical =</span> <span class="ot">TRUE</span>,</span>
<span id="cb402-8"><a href="what-is-statistical-testing.html#cb402-8"></a>  <span class="dt">at =</span> <span class="kw">c</span>(<span class="fl">1.2</span>, <span class="fl">1.8</span>),</span>
<span id="cb402-9"><a href="what-is-statistical-testing.html#cb402-9"></a>  <span class="dt">group.names =</span> <span class="kw">c</span>(<span class="st">&quot;Testosterone&quot;</span>, <span class="st">&quot;Control&quot;</span>),</span>
<span id="cb402-10"><a href="what-is-statistical-testing.html#cb402-10"></a>  <span class="dt">font.lab =</span> <span class="dv">2</span></span>
<span id="cb402-11"><a href="what-is-statistical-testing.html#cb402-11"></a>)</span></code></pre></div>
<p>This is a fairly complicated function call so let’s quickly go through it before we take a look at our plot.</p>
<div class="sourceCode" id="cb403"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb403-1"><a href="what-is-statistical-testing.html#cb403-1"></a><span class="kw">stripchart</span>(<span class="dt">x=</span><span class="kw">list</span>(patch.diff,patch.diff.control))</span></code></pre></div>
<p>The <code>stripchart()</code> function will draw a stripchart (obvious I know), but it expects a data frame or a vector to take its data from. Because we’ve got two separate vectors of data we have to put them together in a list for the function to be able to access both sets of numbers.</p>
<div class="sourceCode" id="cb404"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb404-1"><a href="what-is-statistical-testing.html#cb404-1"></a>cex=<span class="fl">1.5</span>,</span>
<span id="cb404-2"><a href="what-is-statistical-testing.html#cb404-2"></a>pch =<span class="st"> </span><span class="dv">1</span>,</span>
<span id="cb404-3"><a href="what-is-statistical-testing.html#cb404-3"></a>ylab=<span class="st">&quot;Change in ornament size (mm)&quot;</span></span></code></pre></div>
<p>This argument sets the graphical parameter <code>cex</code> (<strong>c</strong>haracter <strong>ex</strong>pansion) to 1.5, meaning that the plot symbols will be 1.5 times the default size, so we’re making R draw the plot symbols a bit bigger than usual. <code>pch = 1</code> sets the plot symbols to open circles rather than the default squares. The <code>ylab="Change in ornament size (mm)"</code> argument tells it how to label the Y axis.</p>
<div class="sourceCode" id="cb405"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb405-1"><a href="what-is-statistical-testing.html#cb405-1"></a>vertical=<span class="ot">TRUE</span>,</span>
<span id="cb405-2"><a href="what-is-statistical-testing.html#cb405-2"></a>at=<span class="kw">c</span>(<span class="fl">1.2</span>,<span class="fl">1.8</span>),</span>
<span id="cb405-3"><a href="what-is-statistical-testing.html#cb405-3"></a>group.names=<span class="kw">c</span>(<span class="st">&quot;Testosterone&quot;</span>,<span class="st">&quot;Control&quot;</span>),</span>
<span id="cb405-4"><a href="what-is-statistical-testing.html#cb405-4"></a>font.lab=<span class="dv">2</span><span class="er">)</span></span></code></pre></div>
<p><code>vertical=TRUE</code> makes R draw the graph with a vertical rather than a horizontal orientation. <code>at=c(1.2,1.8)</code> means that the two strips will be drawn nearer the centre of the X-axis than they would otherwise be. This is because in my opinion the default option had them a bit near the edge of the plot with rather too much empty space between. <code>group.names=c("Testosterone","Control"))</code> tells <code>stripchart()</code> how to label the two groups on the x-axis, and finally <code>font.lab=2</code> puts the axis labels in bold. Putting this all together gives us this graph:</p>
<div class="figure"><span id="fig:test2"></span>
<img src="3rd_Edition_files/figure-html/test2-1.png" alt="Stripchart showing data on changes in dewlap patch size in two groups of lizards" width="672" />
<p class="caption">
Figure 13.2: Stripchart showing data on changes in dewlap patch size in two groups of lizards
</p>
</div>
<p>Looking at the strip chart, there’s a lot of uncertainty regarding whether the effect we’re looking at might just be a chance result. Our two groups have a lot of overlap, even though the majority of one are positive and the majority of the other are negative, so we need to do a statistical test to help us to understand the patterns in the data.</p>
<div id="step-1-generating-our-null-and-alternative-hypotheses." class="section level3">
<h3><span class="header-section-number">13.3.1</span> Step 1 generating our null and alternative hypotheses.</h3>
<p>In this experiment, we don’t really have any prior information about the relationship between testosterone and the size of the red patch on the dewlap. The size of the dewlaps has changed in both groups, so our null hypothesis is that the amount by which the average red patch size has changed is the same in both testosterone and control groups, and our alternative hypothesis is that it is different.</p>
</div>
<div id="step-2-calculating-the-size-of-the-effect" class="section level3">
<h3><span class="header-section-number">13.3.2</span> Step 2 calculating the size of the effect</h3>
<p>We need to quantify the difference between the two groups, and then ask how likely we would be to see that difference if the two groups were drawn from populations with the same means and standard deviations. The difference between the two groups can be calculated as <span class="math inline">\(\bar{x}_{1} - \bar{x}_{2}\)</span>, or the mean of group 1 minus the mean of group 2.</p>
<div class="sourceCode" id="cb406"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb406-1"><a href="what-is-statistical-testing.html#cb406-1"></a>mean.diff &lt;-<span class="st"> </span><span class="kw">mean</span>(patch.diff) <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(patch.diff.control)</span>
<span id="cb406-2"><a href="what-is-statistical-testing.html#cb406-2"></a>mean.diff</span>
<span id="cb406-3"><a href="what-is-statistical-testing.html#cb406-3"></a>[<span class="dv">1</span>] <span class="fl">1.836</span></span></code></pre></div>
<p>This gives us the difference between the means. If the two means were sampled from the same population, most of the time we would expect to find no difference or a very small difference, but sometimes we would find a larger difference by chance. Very occasionally, we would get quite a big negative or positive difference. In other words, if we repeatedly took two samples from populations that were actually the same, as the number of samples increased we would expect the distribution of differences to give us a symmetrical, bell-shaped curve: a normal distribution, or something close to one. We’ve already seen a similar phenomenon in the first example we looked at, but let’s use R to make that point again.</p>
<div class="sourceCode" id="cb407"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb407-1"><a href="what-is-statistical-testing.html#cb407-1"></a>diffs10 &lt;-</span>
<span id="cb407-2"><a href="what-is-statistical-testing.html#cb407-2"></a><span class="st">  </span><span class="kw">apply</span>(<span class="kw">replicate</span>(<span class="dv">10</span>, <span class="kw">rnorm</span>(<span class="dv">10</span>, <span class="dv">5</span>, <span class="dv">2</span>)), <span class="dv">2</span>, mean) <span class="op">-</span><span class="st"> </span><span class="kw">apply</span>(<span class="kw">replicate</span>(<span class="dv">10</span>, <span class="kw">rnorm</span>(<span class="dv">10</span>, <span class="dv">5</span>, <span class="dv">2</span>)), <span class="dv">2</span>, mean)</span>
<span id="cb407-3"><a href="what-is-statistical-testing.html#cb407-3"></a></span>
<span id="cb407-4"><a href="what-is-statistical-testing.html#cb407-4"></a>diffs100 &lt;-</span>
<span id="cb407-5"><a href="what-is-statistical-testing.html#cb407-5"></a><span class="st">  </span><span class="kw">apply</span>(<span class="kw">replicate</span>(<span class="dv">100</span>, <span class="kw">rnorm</span>(<span class="dv">10</span>, <span class="dv">5</span>, <span class="dv">2</span>)), <span class="dv">2</span>, mean) <span class="op">-</span><span class="st"> </span><span class="kw">apply</span>(<span class="kw">replicate</span>(<span class="dv">100</span>, <span class="kw">rnorm</span>(<span class="dv">10</span>, <span class="dv">5</span>, <span class="dv">2</span>)), <span class="dv">2</span>, mean)</span>
<span id="cb407-6"><a href="what-is-statistical-testing.html#cb407-6"></a></span>
<span id="cb407-7"><a href="what-is-statistical-testing.html#cb407-7"></a>diffs1000 &lt;-</span>
<span id="cb407-8"><a href="what-is-statistical-testing.html#cb407-8"></a><span class="st">  </span><span class="kw">apply</span>(<span class="kw">replicate</span>(<span class="dv">1000</span>, <span class="kw">rnorm</span>(<span class="dv">10</span>, <span class="dv">5</span>, <span class="dv">2</span>)), <span class="dv">2</span>, mean) <span class="op">-</span><span class="st"> </span><span class="kw">apply</span>(<span class="kw">replicate</span>(<span class="dv">1000</span>, <span class="kw">rnorm</span>(<span class="dv">10</span>, <span class="dv">5</span>, <span class="dv">2</span>)), <span class="dv">2</span>, mean)</span></code></pre></div>
<p>This code will generate three vectors. <code>diffs10</code> contains 10 numbers, each a difference between the means of two sets of 10 numbers randomly drawn from a normal distribution with a mean of 5 and standard deviation 2: in other words, the differences between 10 means of datasets drawn at random from identical underlying populations. <code>diffs100</code> is the same but with 100 differences and <code>diffs1000</code> has (in case you can’t guess) 1000 differences. Here are the frequency distributions of the differences.</p>
<div class="sourceCode" id="cb408"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb408-1"><a href="what-is-statistical-testing.html#cb408-1"></a></span>
<span id="cb408-2"><a href="what-is-statistical-testing.html#cb408-2"></a><span class="co"># Set plot area to have three figures side by side</span></span>
<span id="cb408-3"><a href="what-is-statistical-testing.html#cb408-3"></a><span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">3</span>))</span>
<span id="cb408-4"><a href="what-is-statistical-testing.html#cb408-4"></a></span>
<span id="cb408-5"><a href="what-is-statistical-testing.html#cb408-5"></a><span class="co"># Histogram of 10 random differences</span></span>
<span id="cb408-6"><a href="what-is-statistical-testing.html#cb408-6"></a><span class="kw">hist</span>(diffs10,</span>
<span id="cb408-7"><a href="what-is-statistical-testing.html#cb408-7"></a>     <span class="dt">col =</span> <span class="st">&#39;grey&#39;</span>,</span>
<span id="cb408-8"><a href="what-is-statistical-testing.html#cb408-8"></a>     <span class="dt">main =</span> <span class="st">&quot;Sample size =10&quot;</span>,</span>
<span id="cb408-9"><a href="what-is-statistical-testing.html#cb408-9"></a>     <span class="dt">font.lab =</span> <span class="dv">2</span>)</span>
<span id="cb408-10"><a href="what-is-statistical-testing.html#cb408-10"></a></span>
<span id="cb408-11"><a href="what-is-statistical-testing.html#cb408-11"></a><span class="co"># Histogram of 100 random differences</span></span>
<span id="cb408-12"><a href="what-is-statistical-testing.html#cb408-12"></a><span class="kw">hist</span>(diffs100,</span>
<span id="cb408-13"><a href="what-is-statistical-testing.html#cb408-13"></a>     <span class="dt">col =</span> <span class="st">&#39;grey&#39;</span>,</span>
<span id="cb408-14"><a href="what-is-statistical-testing.html#cb408-14"></a>     <span class="dt">main =</span> <span class="st">&quot;Sample size =100&quot;</span>,</span>
<span id="cb408-15"><a href="what-is-statistical-testing.html#cb408-15"></a>     <span class="dt">font.lab =</span> <span class="dv">2</span>)</span>
<span id="cb408-16"><a href="what-is-statistical-testing.html#cb408-16"></a></span>
<span id="cb408-17"><a href="what-is-statistical-testing.html#cb408-17"></a><span class="co"># Histogram of 1000 random differences</span></span>
<span id="cb408-18"><a href="what-is-statistical-testing.html#cb408-18"></a><span class="kw">hist</span>(diffs1000,</span>
<span id="cb408-19"><a href="what-is-statistical-testing.html#cb408-19"></a>     <span class="dt">col =</span> <span class="st">&#39;grey&#39;</span>,</span>
<span id="cb408-20"><a href="what-is-statistical-testing.html#cb408-20"></a>     <span class="dt">main =</span> <span class="st">&quot;Sample size =1000&quot;</span>,</span>
<span id="cb408-21"><a href="what-is-statistical-testing.html#cb408-21"></a>     <span class="dt">font.lab =</span> <span class="dv">2</span>)</span></code></pre></div>
<div class="figure"><span id="fig:unnamed-chunk-412"></span>
<img src="3rd_Edition_files/figure-html/unnamed-chunk-412-1.png" alt="Histograms showing frequency distributions for randomly generated differences between means for sample sizes of 10, 100 and 1000" width="768" />
<p class="caption">
Figure 13.3: Histograms showing frequency distributions for randomly generated differences between means for sample sizes of 10, 100 and 1000
</p>
</div>
<div class="sourceCode" id="cb409"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb409-1"><a href="what-is-statistical-testing.html#cb409-1"></a></span>
<span id="cb409-2"><a href="what-is-statistical-testing.html#cb409-2"></a><span class="co"># Set plot area back to the default</span></span>
<span id="cb409-3"><a href="what-is-statistical-testing.html#cb409-3"></a><span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">1</span>))</span></code></pre></div>
<p>As you can see, and as we also saw earlier, when the number of samples is large the distribution of the differences approaches a normal distribution. In the particular case of the data we’ve just simulated, if you were comparing two samples and you got a difference of 1 it would be hard to justify drawing much inference from it, since that difference could represent a real difference between the populations, but it could very easily have arisen because of random sampling from two identical populations. If you got a difference between means of 5, on the other hand, you would know that a difference that large would only very rarely arise by chance, and so the most likely explanation for such a difference would be that the two samples are drawn from different populations.</p>
</div>
<div id="step-3-transforming-the-effect-size-so-that-we-can-compare-it-to-an-expected-distribution." class="section level3">
<h3><span class="header-section-number">13.3.3</span> Step 3 Transforming the effect size so that we can compare it to an expected distribution.</h3>
<p>The difference between our two means is 1.836. Can we not just compare it with a normal distribution to find out how often we should expect it? Unfortunately the answer is “no” for two reasons. The first reason is that although the prediction that if the two populations are the same our mean should come from a distribution with mean zero will always be true, the variance of the distribution of differences will depend on the variances of the distributions the samples are drawn from. We can address this problem in one of two ways.We could calculate the variance of our difference and use that to calculate the shape of the hypothetical distribution that our difference between samples would come from if there were no difference in the populations, or alternatively we could <em>standardise</em> the difference between our means by dividing it by its standard deviation - this latter is the option that people usually choose. Even when we have standardised our difference between means we can’t just see where it lies on a normal distribution, however, because of the second of the two reasons mentioned above, which is that we are only estimating this standard deviation - we don’t know what it is for sure. If we did know the actual value of the population standard deviations that our samples are from we could regard our standardised difference between means as having come from a distribution with a mean of zero and a standard deviation of one - what’s called a <em>standard normal distribution</em>. We only have an estimate of the standard deviations, however, and this is likely to give slight overestimates of the standardised difference between means, so the distribution that we would expect our standardised difference to follow is a not a normal distribution but a related distribution called the <em>t-distribution</em>. This is similar to the normal distribution but is a little less pointy and has slightly fatter “tails”. It also changes shape according to the sample size, or rather according to the number of <em>degrees of freedom</em> of the sample.</p>
<p>There isn’t space here for a full explanation of degrees of freedom (usually abbreviated to “df”) here but think of them as representing the number of values in a set of data that are free to vary, given the parameters you’ve estimated from that data set. Thus, if you have a set of four numbers, and you know the mean, then three of those numbers can vary, but if three of them are varying then the fourth will have its value set because we know the value of the mean. If that sounds strange then you’re not the only person to think that, but there are good reasons for using df instead of sample size for a lot of calculations in statistics.</p>
<p>Here are some t-distributions compared with a normal distribution.</p>
<div class="sourceCode" id="cb410"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb410-1"><a href="what-is-statistical-testing.html#cb410-1"></a></span>
<span id="cb410-2"><a href="what-is-statistical-testing.html#cb410-2"></a><span class="co"># Generate 200 x values between -4 and 4</span></span>
<span id="cb410-3"><a href="what-is-statistical-testing.html#cb410-3"></a>X1 &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="op">-</span><span class="dv">4</span>, <span class="dv">4</span>, <span class="dt">length =</span> <span class="dv">200</span>)</span>
<span id="cb410-4"><a href="what-is-statistical-testing.html#cb410-4"></a></span>
<span id="cb410-5"><a href="what-is-statistical-testing.html#cb410-5"></a><span class="co"># Generate the probability density for a standard normal distribution</span></span>
<span id="cb410-6"><a href="what-is-statistical-testing.html#cb410-6"></a>Y1 &lt;-<span class="st"> </span><span class="kw">dnorm</span>(X1)</span>
<span id="cb410-7"><a href="what-is-statistical-testing.html#cb410-7"></a></span>
<span id="cb410-8"><a href="what-is-statistical-testing.html#cb410-8"></a><span class="co"># Generate the probability density for three t-distributions with varying df</span></span>
<span id="cb410-9"><a href="what-is-statistical-testing.html#cb410-9"></a>Y2 &lt;-<span class="st"> </span><span class="kw">dt</span>(X1, <span class="dv">1</span>)</span>
<span id="cb410-10"><a href="what-is-statistical-testing.html#cb410-10"></a>Y3 &lt;-<span class="st"> </span><span class="kw">dt</span>(X1, <span class="dv">3</span>)</span>
<span id="cb410-11"><a href="what-is-statistical-testing.html#cb410-11"></a>Y4 &lt;-<span class="st"> </span><span class="kw">dt</span>(X1, <span class="dv">8</span>)</span>
<span id="cb410-12"><a href="what-is-statistical-testing.html#cb410-12"></a></span>
<span id="cb410-13"><a href="what-is-statistical-testing.html#cb410-13"></a><span class="co"># Plot the figure with the normal disribution</span></span>
<span id="cb410-14"><a href="what-is-statistical-testing.html#cb410-14"></a><span class="kw">plot</span>(</span>
<span id="cb410-15"><a href="what-is-statistical-testing.html#cb410-15"></a>  X1,</span>
<span id="cb410-16"><a href="what-is-statistical-testing.html#cb410-16"></a>  Y1,</span>
<span id="cb410-17"><a href="what-is-statistical-testing.html#cb410-17"></a>  <span class="dt">xlab =</span> <span class="st">&quot;x&quot;</span>,</span>
<span id="cb410-18"><a href="what-is-statistical-testing.html#cb410-18"></a>  <span class="dt">ylab =</span> <span class="st">&quot;p(x)&quot;</span>,</span>
<span id="cb410-19"><a href="what-is-statistical-testing.html#cb410-19"></a>  <span class="dt">type =</span> <span class="st">&quot;l&quot;</span>,</span>
<span id="cb410-20"><a href="what-is-statistical-testing.html#cb410-20"></a>  <span class="dt">font.lab =</span> <span class="dv">2</span></span>
<span id="cb410-21"><a href="what-is-statistical-testing.html#cb410-21"></a>)</span>
<span id="cb410-22"><a href="what-is-statistical-testing.html#cb410-22"></a></span>
<span id="cb410-23"><a href="what-is-statistical-testing.html#cb410-23"></a><span class="co"># Add the t-distributions</span></span>
<span id="cb410-24"><a href="what-is-statistical-testing.html#cb410-24"></a><span class="kw">points</span>(X1, Y2, <span class="dt">col =</span> <span class="st">&quot;darkblue&quot;</span>, <span class="dt">type =</span> <span class="st">&quot;l&quot;</span>)</span>
<span id="cb410-25"><a href="what-is-statistical-testing.html#cb410-25"></a><span class="kw">points</span>(X1, Y3, <span class="dt">col =</span> <span class="st">&quot;darkgreen&quot;</span>, <span class="dt">type =</span> <span class="st">&quot;l&quot;</span>)</span>
<span id="cb410-26"><a href="what-is-statistical-testing.html#cb410-26"></a><span class="kw">points</span>(X1, Y4, <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">type =</span> <span class="st">&quot;l&quot;</span>)</span>
<span id="cb410-27"><a href="what-is-statistical-testing.html#cb410-27"></a></span>
<span id="cb410-28"><a href="what-is-statistical-testing.html#cb410-28"></a><span class="co"># Add a legend</span></span>
<span id="cb410-29"><a href="what-is-statistical-testing.html#cb410-29"></a><span class="kw">legend</span>(</span>
<span id="cb410-30"><a href="what-is-statistical-testing.html#cb410-30"></a>  <span class="st">&quot;topright&quot;</span>,</span>
<span id="cb410-31"><a href="what-is-statistical-testing.html#cb410-31"></a>  <span class="dt">legend =</span> <span class="kw">c</span>(<span class="st">&quot;Normal&quot;</span>, <span class="st">&quot;t, df=8&quot;</span>, <span class="st">&quot;t, df=3&quot;</span>, <span class="st">&quot;t, df=1&quot;</span>),</span>
<span id="cb410-32"><a href="what-is-statistical-testing.html#cb410-32"></a>  <span class="dt">fill =</span> <span class="kw">c</span>(<span class="st">&quot;black&quot;</span>, <span class="st">&quot;red&quot;</span>, <span class="st">&quot;darkblue&quot;</span>, <span class="st">&quot;darkgreen&quot;</span>),</span>
<span id="cb410-33"><a href="what-is-statistical-testing.html#cb410-33"></a>  <span class="dt">bty =</span> <span class="st">&quot;n&quot;</span></span>
<span id="cb410-34"><a href="what-is-statistical-testing.html#cb410-34"></a>)</span></code></pre></div>
<p>To show the difference between the t-distribution and a normal distribution I’ve used the built in functions in R for calculating probability densities to plot a normal distribution and several different t-distributions. First I used <code>seq()</code> to set up an x-variable with 200 values running from -4 to 4, and then I calculated the probability densities for each x-value assuming a standard normal distribution using the function dnorm(). I then used the <code>dt()</code> function to calculate probability densities for three separate t-distributions, on 1,3 and 8 degrees of freedom, and then I plotted them all onto the same graph.</p>
<div class="figure"><span id="fig:unnamed-chunk-414"></span>
<img src="3rd_Edition_files/figure-html/unnamed-chunk-414-1.png" alt="Probability density functions for the t-distribution on 1,3 and 8 degrees of freedom compared with the probability density function for a normal distribution" width="672" />
<p class="caption">
Figure 13.4: Probability density functions for the t-distribution on 1,3 and 8 degrees of freedom compared with the probability density function for a normal distribution
</p>
</div>
<p>You can see that when the sample size is very small (1df) the t-distribution is quite different from the normal distribution, and that as the sample size increases it becomes more like the normal distribution. In fact, when the sample size is very large the t-distribution approximates to the normal distribution.</p>
<p>The standard deviation of a difference between two means is a bit complicated and looks like this, where <span class="math inline">\(s^{2}_{1}\)</span> is the variance of sample 1, <span class="math inline">\(n_{1}\)</span> is the sample size of sample 1, <span class="math inline">\(s^{2}_{2}\)</span> the variance of sample 2 and <span class="math inline">\(n_{1}\)</span> the sample size of sample 2:</p>
<p><span class="math display">\[\Large \sqrt{\frac{s^{2}_{1}}{n_1} + \frac{s^{2}_{2}}{n_2}}\]</span></p>
<p>So the formula for our standardised difference between means is:</p>
<p><span class="math display">\[\Large standardised\;\: difference  = \frac{\bar{x}_{1} - \bar{x}_{2}}{\sqrt{\frac{s^{2}_{1}}{n_1} + \frac{s^{2}_{2}}{n_2}}}\]</span></p>
<p>To calculate this in R we can use:</p>
<div class="sourceCode" id="cb411"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb411-1"><a href="what-is-statistical-testing.html#cb411-1"></a>mean.diff.t &lt;-</span>
<span id="cb411-2"><a href="what-is-statistical-testing.html#cb411-2"></a><span class="st">  </span>mean.diff <span class="op">/</span><span class="st"> </span><span class="kw">sqrt</span>((<span class="kw">var</span>(patch.diff) <span class="op">/</span><span class="st"> </span><span class="dv">10</span>) <span class="op">+</span><span class="st"> </span></span>
<span id="cb411-3"><a href="what-is-statistical-testing.html#cb411-3"></a><span class="st">                     </span>(<span class="kw">var</span>(patch.diff.control) <span class="op">/</span><span class="st"> </span><span class="dv">10</span>))</span>
<span id="cb411-4"><a href="what-is-statistical-testing.html#cb411-4"></a>mean.diff.t</span>
<span id="cb411-5"><a href="what-is-statistical-testing.html#cb411-5"></a>[<span class="dv">1</span>] <span class="fl">2.8163</span></span></code></pre></div>
<p>We get a final number of 2.816 for the standardised difference between the means, which we would usually call the “test statistic” and which would normally be represented by <em>t</em> because, in case you haven’t worked it out yet, we’re doing a <em>t-test</em>. Now we need to ask what the probability is of observing this value of <em>t</em> given the null-hypothesis that our samples are from the same population. The final thing we need to know to do this is the number of degrees of freedom we need to specify for the t-distribution to compare it with, and the number to use here is <span class="math inline">\(n_1+n_2-2\)</span>. Both sample sizes are 10, so our degrees of freedom are 18.</p>
<p><a name="return"></a></p>
</div>
<div id="step-4-what-is-the-probability-is-of-observing-an-effect-as-big-or-bigger-than-the-one-we-have-seen-assuming-the-null-hypothesis-to-be-true" class="section level3">
<h3><span class="header-section-number">13.3.4</span> Step 4 What is the probability is of observing an effect as big, or bigger than the one we have seen, assuming the null hypothesis to be true?</h3>
<p>Here’s what the t-distribution looks like at 18 df. <a href="#Fig_5_code">The code for this graph is reproduced at the end of the chapter</a>. It’s quite a long script and would be distracting here.</p>
<div class="figure"><span id="fig:test5"></span>
<img src="3rd_Edition_files/figure-html/test5-1.png" alt="Probability density function for the t-distribution on 18 degrees of freedom. The shaded areas show the regions of the graph where we would expect 66%, 95% and 99% of the values of t to fall assuming that the populations sampled are the same" width="672" />
<p class="caption">
Figure 13.5: Probability density function for the t-distribution on 18 degrees of freedom. The shaded areas show the regions of the graph where we would expect 66%, 95% and 99% of the values of t to fall assuming that the populations sampled are the same
</p>
</div>
<p>Because we can describe the t-distribution mathematically, we can use what’s called the <em>cumulative distribution function</em> to calculate its <em>quantiles</em>. These are specific values for which the probability that x will be less than, or greater than that value is known: for example, the central quantile of a distribution is also known as the <em>median</em> (familiar?) and the probability that a randomly chosen value of x will be less than the median is 0.5. Similarly, if we divide the distribution up into four then the quantiles are known as the <em>quartiles</em> and the probability that a random value of x will be less than the third quartile is 0.75. The probability that it will be at least x, or greater, is 1-0.75 which is of course 0.25. In the above graph we’ve used the <code>qt()</code> function to calculate the values of the quantiles that 0.05%, 2.5%, 16.6%, 83.3%, 97.5% and 99.5% of any randomly drawn values of <em>t</em> will be less than, and these quantiles define the areas shaded with different shades of blue. Why those particular quantiles? Because if the null hypothesis were true, these quantiles define the regions of the graph where we would expect our value of <em>t</em> 66%, 95% or 99% of the time.</p>
<p>The region defined by the two darkest areas is the part of the graph which is below the 0.5% quantile or above the 99.5% quantile - so 0.5% of t-values will be in the lower tail and 0.5% in the upper tail, meaning that only 1% of the time should we see a t-value in these areas, if our t-values are calculated using data drawn from the same population. In other words — here comes the whole point of all of the annoying maths and associated guff above — <strong>if the null hypothesis were true, then we would be very unlikely to end up with a calculated value of <em>t</em> in one of these dark blue tails. So if we did have a value of <em>t</em> that fell in this region we could take this as evidence that supports the idea that our samples were in fact drawn from <em>different</em> populations</strong>. In other words, if <em>t</em> is in one of those tails the probability of observing it given the null hypothesis is &lt;0.01, so we <em>reject the null hypothesis</em> at the 1% level and provisionally accept the alternative.</p>
<p>When we combine this araa with the mid-blue area outside the 2.5% and 97.5% quantiles we have a region that contains 5% of the area under the graph, so only 5% of the t-values would be expected to fall in this area if our samples were drawn from the same population. If our calculated value of <em>t</em> is in one of these regions then we know that the probability that we would see a value this large or larger if the two samples were drawn from the same population is, at most, 5% or 1 in 20. Once again, because p&lt;0.05 we reject the null hypothesis, but this time at the 5% level and accept the alternative, rather more tentatively than before.</p>
<p>Continuing in the same vein, combining this 5% area with the pale blue area defined by the 16.6% and 83.3% quantiles shows us where we would expect a t-value to fall 33.3% of the time assuming the source populations are the same, and the white area is 66.6% of the area under the graph, so two thirds of the time we would expect a t-value to fall in this region if the populations used to supply the samples being compared are the same. If we were to calculate a value of <em>t</em> that was in one of these areas we would have to conclude that there is little to suggest the two samples did not come from the same distribution. This time we would say that we have failed to reject the null hypothesis, or that there is <em>no statistically significant difference between our means</em>.</p>
<p>The value of <em>t</em> that we calculated for our lizards is marked on the graph. It’s within the region where 5% of the values of <em>t</em> should lie if the samples they were calculated from were drawn from the same population, but it’s not (quite) in the region where only 1% would be found. We know, therefore, that the probability of observing an effect size this large or larger given the null hypothesis that the two samples of lizards were drawn from populations with the same mean and standard deviation for dewlap patch size, is less than 0.05. 0.05, or 1 in 20 is the conventional cut off for <em>statistical significance</em>, so we could say that we had a statistically significant difference between our mean dewlap patch sizes at p&lt;0.05.</p>
<p>The conventional cutoffs for statistical significance that you will often see, especially in older publications, at p&lt;0.05, p&lt;0.01 and p&lt;0.001, are used because in the days when we calculated our <em>test statistics</em> by hand we compared them with published tables of <em>critical values</em>, and often the only information we would have was that our test statistic was within a particular region of the t-distribution at that number of degrees of freedom. Nowadays we have computers to do our stats for us, and these can easily give us exact p-values for our test statistics. In the case of our lizards we can calculate this as:</p>
<div class="sourceCode" id="cb412"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb412-1"><a href="what-is-statistical-testing.html#cb412-1"></a><span class="dv">2</span><span class="op">*</span>(<span class="dv">1</span><span class="op">-</span><span class="kw">pt</span>(<span class="fl">2.81</span>,<span class="dv">18</span>))</span>
<span id="cb412-2"><a href="what-is-statistical-testing.html#cb412-2"></a>[<span class="dv">1</span>] <span class="fl">0.011586</span></span></code></pre></div>
<p>which gives us a value that, as we can predict from the graph, is between 0.05 and 0.01, and quite close to 0.01. The <code>pt()</code> function gives us the probability of observing a specific value of <em>t</em> or less given a specified number of degrees of freedom, so we subtract this from 1 to give the probability of observing that value or more, and we multiply by two because we are interested in the probability of seeing our value of <em>t</em> in either a positive or a negative tail of the <em>t</em> distribution. In other words, we are carrying out a <em>two-tailed test</em>.</p>
<div id="doing-the-same-test-the-easy-way" class="section level4">
<h4><span class="header-section-number">13.3.4.1</span> Doing the same test the easy way</h4>
<p>Of course, the reason we use R is so that we don’t have to go through the complicated procedure above. R has a built in function to do a t-test for us and we can obtain our p-value with a single, simple function call.</p>
<div class="sourceCode" id="cb413"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb413-1"><a href="what-is-statistical-testing.html#cb413-1"></a><span class="kw">t.test</span>(patch.diff.control, patch.diff)</span>
<span id="cb413-2"><a href="what-is-statistical-testing.html#cb413-2"></a></span>
<span id="cb413-3"><a href="what-is-statistical-testing.html#cb413-3"></a>    Welch Two Sample t<span class="op">-</span>test</span>
<span id="cb413-4"><a href="what-is-statistical-testing.html#cb413-4"></a></span>
<span id="cb413-5"><a href="what-is-statistical-testing.html#cb413-5"></a>data<span class="op">:</span><span class="st">  </span>patch.diff.control and patch.diff</span>
<span id="cb413-6"><a href="what-is-statistical-testing.html#cb413-6"></a>t =<span class="st"> </span><span class="fl">-2.82</span>, df =<span class="st"> </span><span class="fl">17.5</span>, p<span class="op">-</span>value =<span class="st"> </span><span class="fl">0.012</span></span>
<span id="cb413-7"><a href="what-is-statistical-testing.html#cb413-7"></a>alternative hypothesis<span class="op">:</span><span class="st"> </span>true difference <span class="cf">in</span> means is not equal to <span class="dv">0</span></span>
<span id="cb413-8"><a href="what-is-statistical-testing.html#cb413-8"></a><span class="dv">95</span> percent confidence interval<span class="op">:</span></span>
<span id="cb413-9"><a href="what-is-statistical-testing.html#cb413-9"></a><span class="st"> </span><span class="fl">-3.20868</span> <span class="fl">-0.46332</span></span>
<span id="cb413-10"><a href="what-is-statistical-testing.html#cb413-10"></a>sample estimates<span class="op">:</span></span>
<span id="cb413-11"><a href="what-is-statistical-testing.html#cb413-11"></a>mean of x mean of y </span>
<span id="cb413-12"><a href="what-is-statistical-testing.html#cb413-12"></a>   <span class="fl">-1.186</span>     <span class="fl">0.650</span> </span></code></pre></div>
<p>The p-value is there in the output. It’s a slightly different value to the one we calculated above for two reasons: firstly, we were using a value of <em>t</em> calculated to 2 decimal places, and R has used more, and secondly the default option for a t-test in R is a Welch two-sample t-test, which takes account of differences in the variance between the two samples, hence the fractional value for the degrees of freedom.</p>
</div>
</div>
</div>
<div id="what-statistical-testing-does-and-doesnt-tell-us" class="section level2">
<h2><span class="header-section-number">13.4</span> What statistical testing does and doesn’t tell us</h2>
<p>We’ve done our statistical test and we have a p-value. This might be close to zero, indicating a significant effect, or it might be close to 1, indicating that we don’t have any reason to reject the null hypothesis. It might also be somewhere in the vicinity of 0.05, perhaps slightly above or slightly below it. How should we interpret these options?</p>
<p>The first thing to remember is exactly what a statistical null-hypothesis significance test tells us. Our test generated a t-value, which is an example of a test statistic: a value calculated from the data and then standardised so that it can be compared with a theoretical distribution. We then calculated a p-value which is <em>the probability, given the null hypothesis, of observing a value of the test statistic which is more extreme than the one that we calculated from the data</em>, and we use some intellectual sleight-of-hand to turn that around to tell us whether we should accept the alternative hypothesis instead. The p-value is most definitely not any kind of indication of whether the alternative hypothesis is true, or even whether the null hypothesis is not true. It is one piece of evidence which we can use to draw inference about the nature of the effect which we are studying. Unfortunately, in the minds of many people, the p-value and particularly the p&lt;0.05 cutoff has assumed an importance which is not justified when you consider what it actually represents.</p>
<p>There are many problems with this overemphasis on statistical significance as determined by the kind of statistical test described here, and these problems have led to some statisticians concluding that the entire logic base of statistical testing is worthless, and that alternative methods such as Bayesian statistics should be used instead (see <a href="http://www.nature.com/news/scientific-method-statistical-errors-1.14700">this article in Nature</a>). While I appreciate these arguments, I do not personally take such an extreme view. My opinion is that traditional null hypothesis testing is useful so long as the user remembers that:</p>
<ul>
<li>the p&lt;0.05 significance cutoff is an arbitrary line dictated by convention rather than by logic</li>
<li>1 in 20 signficance tests will give a false positive result (a <em>type 1 error</em>) when the null hypothesis is in fact true</li>
<li>most of the time, the two things that are really important are the <strong>magnitude of the effect</strong> and <strong>how precise our estimates of the effect are</strong>, and this is what we should focus on in our interpretation of our results</li>
</ul>
<p>What are the implications of these three points? Firstly, the arbitrariness of the p&lt;0.05 significance level. Statistical significance has acquired such importance in the minds of many that whether a p-value for a study lies on one side or the other of this value is sometimes seen as being the final decider of the success of an experiment or a research project, the value of a three or four year PhD or even the worth of a whole career. This is a corrosive and unscientific attitude, but one which is unfortunately very common in many areas of science. If you have a p-value of 0.049 it doesn’t mean that you have found an effect whereas the person next to you on the bench with a p-value of 0.051 has not - what this means is that there is fractionally less uncertainty about your findings than those of your colleague. We should use p-values as a guide, not as the final dividing line between truth and fiction or between success and failure. We’re doing science in order to find out how the universe works, and if we want to be good scientists we need to be open and honest about the amount of uncertainty in our work.</p>
<p>Secondly, the probability of a false positive result. This means that we need to be careful of (for example) doing large numbers of small experiments, or doing experiments that provide lots and lots of different kinds of data and then carrying out many separate analyses on those data. These “fishing expeditions” are likely to “spit out” false positive results and should be avoided in favour of well designed studies with large sample sizes which address specific and carefully chosen hypotheses. <a href="http://pss.sagepub.com/content/22/11/1359.full">This paper</a>, on what the authors dub the “researcher degrees of freedom” problem is well worth reading in this context. Associated with this problem is the related problem of “p-hacking”, whereby a researcher employs different analyses or removes subgroups of data until a significant result is found. This practice is unlikely to contribute greatly to the advancement of human knowledge.</p>
<p>Thirdly, when we’re interpreting our results the size of the effect is what really matters. It is quite possible to have a significant relationship between two variables that has a vanishingly small effect, especially when sample sizes are high, and when this happens we should always question whether this very small, yet significant effect has much (or any) importance in the real world. In our lizard example above, the estimated effect size is 1.836, and if you look at the output from the t-test you can see that R helpfully gives us confidence intervals of -3.2087 to -0.4633 for this estimate. We should think about this in terms of the system we’re working on, so our discussion should be focussed on the observation that lizards with testosterone supplementation had, on average, red patches with a diameter roughly 1.8mm bigger than those without, and that the 95% confidence intervals for this difference range from -3.2 to -0.46, so we are reasonably sure that testosterone supplementation leads to a change in the diameter of the red dewlap patches of somewhere between these values.</p>
<hr />
<p><a name="Fig_5_code"></a></p>
</div>
<div id="code-used-to-draw-figure-5" class="section level2">
<h2><span class="header-section-number">13.5</span> Code used to draw figure 5</h2>
<p>There’s a lot of code used to draw this figure so we won’t go through it in detail, but some things you might note are that we use qt() to give the quantile values for the t-distribution which then define the regions plotted; that the polygon() function is what draws in the shaded areas; that there are hexadecimal numbers to define the colours because I couldn’t find named colours that looked quite as I wanted; and that the “\n” symbol in the last text string makes carriage returns. If this is all a bit much don’t worry, just look at the graph. <a href="#return">Back to the text</a>.</p>
<div class="sourceCode" id="cb414"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb414-1"><a href="what-is-statistical-testing.html#cb414-1"></a>X1 &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="op">-</span><span class="dv">4</span>, <span class="dv">4</span>, <span class="dt">length =</span> <span class="dv">200</span>)</span>
<span id="cb414-2"><a href="what-is-statistical-testing.html#cb414-2"></a>Y1 &lt;-<span class="st"> </span><span class="kw">dt</span>(X1, <span class="dv">18</span>)</span>
<span id="cb414-3"><a href="what-is-statistical-testing.html#cb414-3"></a><span class="kw">plot</span>(</span>
<span id="cb414-4"><a href="what-is-statistical-testing.html#cb414-4"></a>  X1,</span>
<span id="cb414-5"><a href="what-is-statistical-testing.html#cb414-5"></a>  Y1,</span>
<span id="cb414-6"><a href="what-is-statistical-testing.html#cb414-6"></a>  <span class="dt">type =</span> <span class="st">&quot;n&quot;</span>,</span>
<span id="cb414-7"><a href="what-is-statistical-testing.html#cb414-7"></a>  <span class="dt">xlab =</span> <span class="st">&quot;x&quot;</span>,</span>
<span id="cb414-8"><a href="what-is-statistical-testing.html#cb414-8"></a>  <span class="dt">ylab =</span> <span class="st">&quot;P(x)&quot;</span>,</span>
<span id="cb414-9"><a href="what-is-statistical-testing.html#cb414-9"></a>  <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="fl">0.42</span>),</span>
<span id="cb414-10"><a href="what-is-statistical-testing.html#cb414-10"></a>  <span class="dt">main =</span> <span class="st">&quot;t-distribution on 18 df&quot;</span></span>
<span id="cb414-11"><a href="what-is-statistical-testing.html#cb414-11"></a>)</span>
<span id="cb414-12"><a href="what-is-statistical-testing.html#cb414-12"></a></span>
<span id="cb414-13"><a href="what-is-statistical-testing.html#cb414-13"></a>x0 &lt;-<span class="st"> </span><span class="kw">min</span>(<span class="kw">which</span>(X1 <span class="op">&gt;=</span><span class="st"> </span><span class="kw">qt</span>(<span class="fl">0.005</span>, <span class="dv">18</span>)))</span>
<span id="cb414-14"><a href="what-is-statistical-testing.html#cb414-14"></a>x1 &lt;-<span class="st"> </span><span class="kw">min</span>(<span class="kw">which</span>(X1 <span class="op">&gt;=</span><span class="st"> </span><span class="kw">qt</span>(<span class="fl">0.025</span>, <span class="dv">18</span>)))</span>
<span id="cb414-15"><a href="what-is-statistical-testing.html#cb414-15"></a>x2 &lt;-<span class="st"> </span><span class="kw">min</span>(<span class="kw">which</span>(X1 <span class="op">&gt;=</span><span class="st"> </span><span class="kw">qt</span>(<span class="fl">0.1666</span>, <span class="dv">18</span>)))</span>
<span id="cb414-16"><a href="what-is-statistical-testing.html#cb414-16"></a>x3 &lt;-<span class="st"> </span><span class="kw">max</span>(<span class="kw">which</span>(X1 <span class="op">&lt;=</span><span class="st"> </span><span class="kw">qt</span>(<span class="fl">0.8333</span>, <span class="dv">18</span>)))</span>
<span id="cb414-17"><a href="what-is-statistical-testing.html#cb414-17"></a>x4 &lt;-<span class="st"> </span><span class="kw">max</span>(<span class="kw">which</span>(X1 <span class="op">&lt;=</span><span class="st"> </span><span class="kw">qt</span>(<span class="fl">0.975</span>, <span class="dv">18</span>)))</span>
<span id="cb414-18"><a href="what-is-statistical-testing.html#cb414-18"></a>x5 &lt;-<span class="st"> </span><span class="kw">max</span>(<span class="kw">which</span>(X1 <span class="op">&lt;=</span><span class="st"> </span><span class="kw">qt</span>(<span class="fl">0.995</span>, <span class="dv">18</span>)))</span>
<span id="cb414-19"><a href="what-is-statistical-testing.html#cb414-19"></a></span>
<span id="cb414-20"><a href="what-is-statistical-testing.html#cb414-20"></a><span class="kw">polygon</span>(</span>
<span id="cb414-21"><a href="what-is-statistical-testing.html#cb414-21"></a>  <span class="dt">x =</span> <span class="kw">c</span>(X1[<span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">1</span><span class="op">:</span>x0, x0)]),</span>
<span id="cb414-22"><a href="what-is-statistical-testing.html#cb414-22"></a>  <span class="dt">y =</span> <span class="kw">c</span>(<span class="dv">0</span>, Y1[<span class="dv">1</span><span class="op">:</span>x0], <span class="dv">0</span>),</span>
<span id="cb414-23"><a href="what-is-statistical-testing.html#cb414-23"></a>  <span class="dt">col =</span> <span class="st">&quot;#3182bd&quot;</span>,</span>
<span id="cb414-24"><a href="what-is-statistical-testing.html#cb414-24"></a>  <span class="dt">border =</span> <span class="ot">NA</span></span>
<span id="cb414-25"><a href="what-is-statistical-testing.html#cb414-25"></a>)</span>
<span id="cb414-26"><a href="what-is-statistical-testing.html#cb414-26"></a><span class="kw">polygon</span>(</span>
<span id="cb414-27"><a href="what-is-statistical-testing.html#cb414-27"></a>  <span class="dt">x =</span> <span class="kw">c</span>(X1[<span class="kw">c</span>(x0, x0<span class="op">:</span>x1, x1)]),</span>
<span id="cb414-28"><a href="what-is-statistical-testing.html#cb414-28"></a>  <span class="dt">y =</span> <span class="kw">c</span>(<span class="dv">0</span>, Y1[x0<span class="op">:</span>x1], <span class="dv">0</span>),</span>
<span id="cb414-29"><a href="what-is-statistical-testing.html#cb414-29"></a>  <span class="dt">col =</span> <span class="st">&quot;#9ecae1&quot;</span>,</span>
<span id="cb414-30"><a href="what-is-statistical-testing.html#cb414-30"></a>  <span class="dt">border =</span> <span class="ot">NA</span></span>
<span id="cb414-31"><a href="what-is-statistical-testing.html#cb414-31"></a>)</span>
<span id="cb414-32"><a href="what-is-statistical-testing.html#cb414-32"></a><span class="kw">polygon</span>(</span>
<span id="cb414-33"><a href="what-is-statistical-testing.html#cb414-33"></a>  <span class="dt">x =</span> <span class="kw">c</span>(X1[<span class="kw">c</span>(x1, x1<span class="op">:</span>x2, x2)]),</span>
<span id="cb414-34"><a href="what-is-statistical-testing.html#cb414-34"></a>  <span class="dt">y =</span> <span class="kw">c</span>(<span class="dv">0</span>, Y1[x1<span class="op">:</span>x2], <span class="dv">0</span>),</span>
<span id="cb414-35"><a href="what-is-statistical-testing.html#cb414-35"></a>  <span class="dt">col =</span> <span class="st">&quot;#deebf7&quot;</span>,</span>
<span id="cb414-36"><a href="what-is-statistical-testing.html#cb414-36"></a>  <span class="dt">border =</span> <span class="ot">NA</span></span>
<span id="cb414-37"><a href="what-is-statistical-testing.html#cb414-37"></a>)</span>
<span id="cb414-38"><a href="what-is-statistical-testing.html#cb414-38"></a><span class="kw">polygon</span>(</span>
<span id="cb414-39"><a href="what-is-statistical-testing.html#cb414-39"></a>  <span class="dt">x =</span> <span class="kw">c</span>(X1[<span class="kw">c</span>(x2, x2<span class="op">:</span>x3, x3)]),</span>
<span id="cb414-40"><a href="what-is-statistical-testing.html#cb414-40"></a>  <span class="dt">y =</span> <span class="kw">c</span>(<span class="dv">0</span>, Y1[x2<span class="op">:</span>x3], <span class="dv">0</span>),</span>
<span id="cb414-41"><a href="what-is-statistical-testing.html#cb414-41"></a>  <span class="dt">col =</span> <span class="st">&quot;white&quot;</span>,</span>
<span id="cb414-42"><a href="what-is-statistical-testing.html#cb414-42"></a>  <span class="dt">border =</span> <span class="ot">NA</span></span>
<span id="cb414-43"><a href="what-is-statistical-testing.html#cb414-43"></a>)</span>
<span id="cb414-44"><a href="what-is-statistical-testing.html#cb414-44"></a><span class="kw">polygon</span>(</span>
<span id="cb414-45"><a href="what-is-statistical-testing.html#cb414-45"></a>  <span class="dt">x =</span> <span class="kw">c</span>(X1[<span class="kw">c</span>(x3, x3<span class="op">:</span>x4, x4)]),</span>
<span id="cb414-46"><a href="what-is-statistical-testing.html#cb414-46"></a>  <span class="dt">y =</span> <span class="kw">c</span>(<span class="dv">0</span>, Y1[x3<span class="op">:</span>x4], <span class="dv">0</span>),</span>
<span id="cb414-47"><a href="what-is-statistical-testing.html#cb414-47"></a>  <span class="dt">col =</span> <span class="st">&quot;#deebf7&quot;</span>,</span>
<span id="cb414-48"><a href="what-is-statistical-testing.html#cb414-48"></a>  <span class="dt">border =</span> <span class="ot">NA</span></span>
<span id="cb414-49"><a href="what-is-statistical-testing.html#cb414-49"></a>)</span>
<span id="cb414-50"><a href="what-is-statistical-testing.html#cb414-50"></a><span class="kw">polygon</span>(</span>
<span id="cb414-51"><a href="what-is-statistical-testing.html#cb414-51"></a>  <span class="dt">x =</span> <span class="kw">c</span>(X1[<span class="kw">c</span>(x4, x4<span class="op">:</span>x5, x5)]),</span>
<span id="cb414-52"><a href="what-is-statistical-testing.html#cb414-52"></a>  <span class="dt">y =</span> <span class="kw">c</span>(<span class="dv">0</span>, Y1[x4<span class="op">:</span>x5], <span class="dv">0</span>),</span>
<span id="cb414-53"><a href="what-is-statistical-testing.html#cb414-53"></a>  <span class="dt">col =</span> <span class="st">&quot;#9ecae1&quot;</span>,</span>
<span id="cb414-54"><a href="what-is-statistical-testing.html#cb414-54"></a>  <span class="dt">border =</span> <span class="ot">NA</span></span>
<span id="cb414-55"><a href="what-is-statistical-testing.html#cb414-55"></a>)</span>
<span id="cb414-56"><a href="what-is-statistical-testing.html#cb414-56"></a><span class="kw">polygon</span>(</span>
<span id="cb414-57"><a href="what-is-statistical-testing.html#cb414-57"></a>  <span class="dt">x =</span> <span class="kw">c</span>(X1[<span class="kw">c</span>(x5, x5<span class="op">:</span><span class="dv">200</span>, <span class="dv">200</span>)]),</span>
<span id="cb414-58"><a href="what-is-statistical-testing.html#cb414-58"></a>  <span class="dt">y =</span> <span class="kw">c</span>(<span class="dv">0</span>, Y1[x5<span class="op">:</span><span class="dv">200</span>], <span class="dv">0</span>),</span>
<span id="cb414-59"><a href="what-is-statistical-testing.html#cb414-59"></a>  <span class="dt">col =</span> <span class="st">&quot;#3182bd&quot;</span>,</span>
<span id="cb414-60"><a href="what-is-statistical-testing.html#cb414-60"></a>  <span class="dt">border =</span> <span class="ot">NA</span></span>
<span id="cb414-61"><a href="what-is-statistical-testing.html#cb414-61"></a>)</span>
<span id="cb414-62"><a href="what-is-statistical-testing.html#cb414-62"></a></span>
<span id="cb414-63"><a href="what-is-statistical-testing.html#cb414-63"></a><span class="kw">points</span>(X1, Y1, <span class="dt">type =</span> <span class="st">&quot;l&quot;</span>)</span>
<span id="cb414-64"><a href="what-is-statistical-testing.html#cb414-64"></a></span>
<span id="cb414-65"><a href="what-is-statistical-testing.html#cb414-65"></a><span class="kw">text</span>(<span class="dv">0</span>, Y1[x2] <span class="op">+</span><span class="st"> </span><span class="fl">0.01</span>, <span class="st">&quot;66% of values&quot;</span>, <span class="dt">cex =</span> <span class="fl">0.8</span>)</span>
<span id="cb414-66"><a href="what-is-statistical-testing.html#cb414-66"></a><span class="kw">lines</span>(<span class="kw">c</span>(X1[x2], X1[x3]), <span class="kw">c</span>(Y1[x2] <span class="op">-</span><span class="st"> </span><span class="fl">0.001</span>, Y1[x3] <span class="op">-</span><span class="st"> </span><span class="fl">0.001</span>))</span>
<span id="cb414-67"><a href="what-is-statistical-testing.html#cb414-67"></a></span>
<span id="cb414-68"><a href="what-is-statistical-testing.html#cb414-68"></a><span class="kw">text</span>(<span class="dv">0</span>, Y1[x1] <span class="op">+</span><span class="st"> </span><span class="fl">0.01</span>, <span class="st">&quot;95% of values&quot;</span>, <span class="dt">cex =</span> <span class="fl">0.8</span>)</span>
<span id="cb414-69"><a href="what-is-statistical-testing.html#cb414-69"></a><span class="kw">lines</span>(<span class="kw">c</span>(X1[x1], X1[x4]), <span class="kw">c</span>(Y1[x1] <span class="op">-</span><span class="st"> </span><span class="fl">0.001</span>, Y1[x4] <span class="op">-</span><span class="st"> </span><span class="fl">0.001</span>))</span>
<span id="cb414-70"><a href="what-is-statistical-testing.html#cb414-70"></a></span>
<span id="cb414-71"><a href="what-is-statistical-testing.html#cb414-71"></a><span class="kw">text</span>(<span class="dv">0</span>, Y1[x0] <span class="op">+</span><span class="st"> </span><span class="fl">0.01</span>, <span class="st">&quot;99% of values&quot;</span>, <span class="dt">cex =</span> <span class="fl">0.8</span>)</span>
<span id="cb414-72"><a href="what-is-statistical-testing.html#cb414-72"></a><span class="kw">lines</span>(<span class="kw">c</span>(X1[x0], X1[x5]), <span class="kw">c</span>(Y1[x0] <span class="op">-</span><span class="st"> </span><span class="fl">0.001</span>, Y1[x5] <span class="op">-</span><span class="st"> </span><span class="fl">0.001</span>))</span>
<span id="cb414-73"><a href="what-is-statistical-testing.html#cb414-73"></a></span>
<span id="cb414-74"><a href="what-is-statistical-testing.html#cb414-74"></a><span class="kw">arrows</span>(<span class="fl">2.816</span>, <span class="fl">0.04</span>, <span class="fl">2.816</span>, <span class="kw">dt</span>(<span class="fl">2.816</span>, <span class="dv">18</span>), <span class="dt">length =</span> <span class="fl">0.05</span>)</span>
<span id="cb414-75"><a href="what-is-statistical-testing.html#cb414-75"></a></span>
<span id="cb414-76"><a href="what-is-statistical-testing.html#cb414-76"></a><span class="kw">text</span>(<span class="fl">2.816</span>, <span class="fl">0.06</span>, <span class="st">&quot;Location of</span><span class="ch">\n</span><span class="st"> our calculated</span><span class="ch">\n</span><span class="st"> value of t&quot;</span>, <span class="dt">cex =</span> <span class="fl">0.7</span>)</span></code></pre></div>

</div>
</div>
<div class="footnotes">
<hr />
<ol start="15">
<li id="fn15"><p>Yes, I made these data up. While I try to avoid using made up data for most of the examples in the book, for this section it’s easiest to illustrate the important points with a simple and straightforward dataset. I have learnt to be upfront about it when I use made up data since I got an essay from a student with something I’d made up in a lecture to illustrate a point included as a fact.<a href="what-is-statistical-testing.html#fnref15" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="basic-statistical-concepts.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="the-chi-squared-test-and-a-classic-dataset-on-smoking-and-cancer.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["3rd_Edition.pdf", "3rd_Edition.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
